
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Reducir el overfitting &#8212; Aplicaciones de la Matematica en la Ingenieria</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="shortcut icon" href="../../../../_static/logo_python.jpeg"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Series Temporales" href="../time_series/05_series_temporales.html" />
    <link rel="prev" title="Overfitting" href="04_overfitting_underfitting.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
      <img src="../../../../_static/logo_python.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Aplicaciones de la Matematica en la Ingenieria</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../index.html">
   Home
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Herramientas Básicas
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../basic_tools/lecture_000_intro.html">
   Introducción
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basic_tools/lecture_000_configuraciones.html">
     Configuraciones
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_011_os.html">
   Linux
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_015_git.html">
   Git
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_013_ide.html">
   IDE’s
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_016_venv.html">
   Virtual Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_012_python.html">
   Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_014_jupyter.html">
   Jupyter
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Computación cientifica
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/scientific_computing/numpy.html">
   Numpy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/scientific_computing/scipy.html">
   SciPy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/scientific_computing/sympy.html">
   Sympy
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Manipulación de datos
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/data_manipulation/base_datos.html">
   Base de datos
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data_manipulation/data_manipulation/pandas/pandas.html">
   Pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/data_manipulation/modulos_pandas/groupby.html">
     Groupby
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/data_manipulation/modulos_pandas/merge_concat.html">
     Merge &amp; Concat
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/data_manipulation/modulos_pandas/pivot.html">
     Pivot
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/data_manipulation/sqlalchemy/sqlalchemy.html">
   SQLAlchemy
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Visualización
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/introduction.html">
   Introducción
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/imperativa.html">
   Visualización Imperativa
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/matplotlib.html">
     Matplotlib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/declarativa.html">
   Visualización Declarativa
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/seaborn.html">
     Seaborn
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Análisis exploratorio de datos
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/eda/intro.html">
   Introducción
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/eda/eda.html">
   Caso Aplicado
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduccion_ml/introduccion.html">
   Introducción
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../analisis_supervisado_regresion/intro.html">
   Aprendizaje supervisado - Regresión
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis_supervisado_regresion/02_regresion_lineal.html">
     Modelos de regressión lineal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis_supervisado_regresion/02_modelos_regresion.html">
     Modelos de regressión multiple
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../analisis_supervisado_clasificacion/intro.html">
   Aprendizaje supervisado - Clasificación
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis_supervisado_clasificacion/02_clasificacion.html">
     Modelo de regresión logística
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../introduccion_ml/no_supervisados.html">
   Aprendizaje no supervisado
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis_no_supervisado/03_clustering.html">
     Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis_no_supervisado/03_reduccion_dimensionalidad.html">
     Reducción de dimensionalidad
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="04_overfitting_underfitting.html">
   Overfitting
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Reducir el overfitting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../time_series/05_series_temporales.html">
   Series Temporales
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../../_sources/mat281/lectures/ml/overfitting/04_reducir_overfitting.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://gitlab.com/FAAM/mat281_2021"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#validacion-cruzada">
   Validación cruzada
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mas-datos-y-curvas-de-aprendizaje">
     Más datos y curvas de aprendizaje
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizacion-de-parametros-con-grid-search">
   Optimización de parámetros con Grid Search
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reduccion-de-dimensionalidad">
   Reducción de dimensionalidad
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extraccion-de-atributos">
     Extracción de atributos
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#seleccion-de-atributos">
     Selección de atributos
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#referencia">
   Referencia
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="reducir-el-overfitting">
<h1>Reducir el overfitting<a class="headerlink" href="#reducir-el-overfitting" title="Permalink to this headline">¶</a></h1>
<p>Algunas de las técnicas que podemos utilizar para reducir el overfitting, son:</p>
<ul class="simple">
<li><p>Recolectar más datos.</p></li>
<li><p>Introducir una penalización a la complejidad con alguna técnica de regularización.</p></li>
<li><p>Utilizar modelos ensamblados.</p></li>
<li><p>Utilizar validación cruzada.</p></li>
<li><p>Optimizar los parámetros del modelo con <em>grid search</em>.</p></li>
<li><p>Reducir la dimensión de los datos.</p></li>
<li><p>Aplicar técnicas de selección de atributos.</p></li>
</ul>
<p>Veremos ejemplos de algunos métodos para reducir el sobreajuste (overfitting).</p>
<div class="section" id="validacion-cruzada">
<h2>Validación cruzada<a class="headerlink" href="#validacion-cruzada" title="Permalink to this headline">¶</a></h2>
<p>La <strong>validación cruzada</strong> se inicia mediante el fraccionamiento de un conjunto de datos en un número <span class="math notranslate nohighlight">\(k\)</span> de particiones (generalmente entre 5 y 10) llamadas <em>pliegues</em>.</p>
<p>La validación cruzada luego itera entre los datos de <em>evaluación</em> y <em>entrenamiento</em> <span class="math notranslate nohighlight">\(k\)</span> veces, de un modo particular. En cada iteración de la validación cruzada, un <em>pliegue</em> diferente se elige como los datos de <em>evaluación</em>. En esta iteración, los otros <em>pliegues</em> <span class="math notranslate nohighlight">\(k-1\)</span> se combinan para formar los datos de <em>entrenamiento</em>. Por lo tanto, en cada iteración tenemos <span class="math notranslate nohighlight">\((k-1) / k\)</span> de los datos utilizados para el <em>entrenamiento</em> y <span class="math notranslate nohighlight">\(1 / k\)</span> utilizado para la <em>evaluación</em>.</p>
<p>Cada iteración produce un modelo, y por lo tanto una estimación del rendimiento de la <em>generalización</em>, por ejemplo, una estimación de la precisión. Una vez finalizada la validación cruzada, todos los ejemplos se han utilizado sólo una vez para <em>evaluar</em> pero <span class="math notranslate nohighlight">\(k -1\)</span> veces para <em>entrenar</em>. En este punto tenemos estimaciones de rendimiento de todos los <em>pliegues</em> y podemos calcular la media y la desviación estándar de la precisión del modelo.</p>
<a class="reference internal image-reference" href="../../../../_images/validacion_cruzada.png"><img alt="../../../../_images/validacion_cruzada.png" class="align-center" src="../../../../_images/validacion_cruzada.png" style="width: 550px; height: 650px;" /></a>
<p>Veamos un ejemplo en python, ocupando el conjunto de datos <strong>make_classification</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># librerias </span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> 
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span> 
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span><span class="n">DecisionTreeRegressor</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1982</span><span class="p">)</span> <span class="c1"># semilla</span>

<span class="c1"># graficos incrustados</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1"># parametros esteticos de seaborn</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s2">&quot;deep&quot;</span><span class="p">,</span> <span class="n">desat</span><span class="o">=</span><span class="mf">.6</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">)})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ejemplo en python - árboles de decisión</span>
<span class="c1"># dummy data con 100 atributos y 2 clases</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                          <span class="n">random_state</span><span class="o">=</span><span class="mi">1982</span><span class="p">)</span>

<span class="c1"># separ los datos en train y eval</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_eval</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_eval</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.35</span><span class="p">,</span> 
                                                    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.65</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">1982</span><span class="p">)</span>

<span class="c1"># Grafico de ajuste del árbol de decisión</span>
<span class="n">train_prec</span> <span class="o">=</span>  <span class="p">[]</span>
<span class="n">eval_prec</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">max_deep_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ejemplo cross-validation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span><span class="p">,</span><span class="n">StratifiedKFold</span>

<span class="c1"># creando pliegues</span>

<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">precision</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">model</span> <span class="o">=</span>  <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">skf</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span> 
    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
    <span class="n">precision</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Pliegue: </span><span class="si">{0:}</span><span class="s1">, Dist Clase: </span><span class="si">{1:}</span><span class="s1">, Prec: </span><span class="si">{2:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="n">score</span><span class="p">))</span>
    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 1, Dist Clase: [4763 4737], Prec: 0.928
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 2, Dist Clase: [4763 4737], Prec: 0.914
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 3, Dist Clase: [4763 4737], Prec: 0.916
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 4, Dist Clase: [4763 4737], Prec: 0.938
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 5, Dist Clase: [4763 4737], Prec: 0.924
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 6, Dist Clase: [4763 4737], Prec: 0.938
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 7, Dist Clase: [4763 4737], Prec: 0.924
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 8, Dist Clase: [4762 4738], Prec: 0.938
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 9, Dist Clase: [4762 4738], Prec: 0.936
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 10, Dist Clase: [4762 4738], Prec: 0.908
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 11, Dist Clase: [4762 4738], Prec: 0.936
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 12, Dist Clase: [4762 4738], Prec: 0.938
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 13, Dist Clase: [4762 4738], Prec: 0.934
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 14, Dist Clase: [4762 4738], Prec: 0.922
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 15, Dist Clase: [4762 4738], Prec: 0.930
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 16, Dist Clase: [4762 4738], Prec: 0.928
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 17, Dist Clase: [4762 4738], Prec: 0.924
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 18, Dist Clase: [4762 4738], Prec: 0.926
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 19, Dist Clase: [4762 4738], Prec: 0.936
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pliegue: 20, Dist Clase: [4762 4738], Prec: 0.920
</pre></div>
</div>
</div>
</div>
<p>En este ejemplo, utilizamos el iterador <code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code> que nos proporciona Scikit-learn. Este iterador es una versión mejorada de la validación cruzada, ya que cada <em>pliegue</em> va a estar estratificado para mantener las proporciones entre las <em>clases</em> del conjunto de datos original, lo que suele dar mejores estimaciones del sesgo y la varianza del modelo.</p>
<p>También podríamos utilizar <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code> que ya nos proporciona los resultados de la precisión que tuvo el modelo en cada <em>pliegue</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ejemplo con cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="c1"># separ los datos en train y eval</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_eval</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_eval</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.35</span><span class="p">,</span> 
                                                    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.65</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">1982</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span>
                               <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>


<span class="n">precision</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                            <span class="n">X</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span>
                            <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
                            <span class="n">cv</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">precision</span> <span class="o">=</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">precision</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precisiones: </span><span class="si">{}</span><span class="s1"> &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precision promedio: </span><span class="si">{0: .3f}</span><span class="s1"> +/- </span><span class="si">{1: .3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">precision</span><span class="p">),</span>
                                          <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">precision</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Precisiones: [0.93, 0.94, 0.92, 0.94, 0.93, 0.9, 0.92, 0.94, 0.94, 0.93, 0.94, 0.92, 0.91, 0.91, 0.93, 0.94, 0.93, 0.93, 0.93, 0.94] 
Precision promedio:  0.928 +/-  0.012
</pre></div>
</div>
</div>
</div>
<div class="section" id="mas-datos-y-curvas-de-aprendizaje">
<h3>Más datos y curvas de aprendizaje<a class="headerlink" href="#mas-datos-y-curvas-de-aprendizaje" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Muchas veces, reducir el Sobreajuste es tan fácil como conseguir más datos, dame más datos y te predeciré el futuro!.</p></li>
<li><p>En la vida real nunca es una tarea tan sencilla conseguir más datos.</p></li>
<li><p>Una técnica para reducir el sobreajuste son las <em>curvas de aprendizaje</em>, las cuales grafican la precisión en función del tamaño de los datos de entrenamiento.</p></li>
</ul>
<a class="reference internal image-reference" href="../../../../_images/curva_aprendizaje.png"><img alt="Curva de aprendizaje" src="../../../../_images/curva_aprendizaje.png" style="width: 600px; height: 600px;" /></a>
<p>Para graficar las curvas de aprendizaje es necesario ocupar el comando de sklearn llamado <code class="docutils literal notranslate"><span class="pre">learning_curve</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ejemplo Curvas de aprendizaje</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span>  <span class="n">learning_curve</span>

<span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
                        <span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                        <span class="n">X</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span>
                        <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> 
                        <span class="n">train_sizes</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
                        <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                        <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
                        <span class="p">)</span>

<span class="c1"># calculo de metricas</span>
<span class="n">train_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Veamos que el comando <code class="docutils literal notranslate"><span class="pre">learning_curve</span></code> va creando conjunto de datos, pero de distintos tamaños.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tamano conjunto de entrenamiento</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Tamaño Conjunto </span><span class="si">{}</span><span class="s1">: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">train_sizes</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tamaño Conjunto 1: 585
Tamaño Conjunto 2: 862
Tamaño Conjunto 3: 1139
Tamaño Conjunto 4: 1416
Tamaño Conjunto 5: 1693
Tamaño Conjunto 6: 1970
Tamaño Conjunto 7: 2247
Tamaño Conjunto 8: 2524
Tamaño Conjunto 9: 2801
Tamaño Conjunto 10: 3078
Tamaño Conjunto 11: 3356
Tamaño Conjunto 12: 3633
Tamaño Conjunto 13: 3910
Tamaño Conjunto 14: 4187
Tamaño Conjunto 15: 4464
Tamaño Conjunto 16: 4741
Tamaño Conjunto 17: 5018
Tamaño Conjunto 18: 5295
Tamaño Conjunto 19: 5572
Tamaño Conjunto 20: 5850
</pre></div>
</div>
</div>
</div>
<p>Finalmente, graficamos las precisiones tanto para el conjunto de entranamiento como de evaluación para los distintos conjuntos de datos generados.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficando las curvas</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_mean</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s1">&#39;entrenamiento&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_mean</span> <span class="o">+</span> <span class="n">train_std</span><span class="p">,</span> 
                 <span class="n">train_mean</span> <span class="o">-</span> <span class="n">train_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_mean</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> 
         <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;evaluacion&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_mean</span> <span class="o">+</span> <span class="n">test_std</span><span class="p">,</span> 
                 <span class="n">test_mean</span> <span class="o">-</span> <span class="n">test_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva de aprendizaje&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Cant de ejemplos de entrenamiento&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Precision&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/04_reducir_overfitting_15_0.png" src="../../../../_images/04_reducir_overfitting_15_0.png" />
</div>
</div>
<p>En este gráfico podemos concluir que:</p>
<ul class="simple">
<li><p>Con pocos datos la precisión entre los datos de entrenamiento y los de evaluación son muy distintas y luego a medida que la cantidad de datos va aumentando, el modelo puede generalizar mucho mejor y las precisiones se comienzan a emparejar.</p></li>
<li><p>Este gráfico también puede ser importante a la hora de decidir invertir en la obtención de más datos, ya que por ejemplo nos indica que a partir las 2500 muestras, el modelo ya no gana mucha más precisión a pesar de obtener más datos.</p></li>
</ul>
</div>
</div>
<div class="section" id="optimizacion-de-parametros-con-grid-search">
<h2>Optimización de parámetros con Grid Search<a class="headerlink" href="#optimizacion-de-parametros-con-grid-search" title="Permalink to this headline">¶</a></h2>
<p>La mayoría de los modelos de Machine Learning cuentan con varios parámetros para ajustar su comportamiento, por lo tanto, otra alternativa que tenemos para reducir el Sobreajuste es optimizar estos parámetros por medio de un proceso conocido como <strong>grid search</strong> e intentar encontrar la combinación ideal que nos proporcione mayor precisión.</p>
<p>El enfoque que utiliza <em>grid search</em> es bastante simple, se trata de una búsqueda exhaustiva por el paradigma de fuerza bruta en el que se especifica una lista de valores para diferentes parámetros, y la computadora evalúa el rendimiento del modelo para cada combinación de éstos parámetros para obtener el conjunto óptimo que nos brinda el mayor rendimiento.</p>
<a class="reference internal image-reference" href="../../../../_images/hyper.png"><img alt="Curva de aprendizaje" src="../../../../_images/hyper.png" style="width: 600px; height: 500px;" /></a>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ejemplo de grid search con SVM.</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="c1"># creación del modelo</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="c1"># rango de parametros</span>
<span class="n">rango_criterion</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span><span class="s1">&#39;entropy&#39;</span><span class="p">]</span>
<span class="n">rango_max_depth</span> <span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">70</span><span class="p">,</span><span class="mi">90</span><span class="p">,</span><span class="mi">120</span><span class="p">,</span><span class="mi">150</span><span class="p">])</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="n">rango_criterion</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">rango_max_depth</span><span class="p">)</span>
<span class="n">param_grid</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;criterion&#39;: [&#39;gini&#39;, &#39;entropy&#39;],
 &#39;max_depth&#39;: array([  4,   5,   6,   7,   8,   9,  10,  11,  12,  15,  20,  30,  40,
         50,  70,  90, 120, 150])}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># aplicar greed search</span>

<span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> 
                  <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> 
                  <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span>
                  <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                  <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">gs</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="mi">7</span><span class="n">bb2e810aec8</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>                   <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> 
<span class="ne">----&gt; </span><span class="mi">9</span> <span class="n">gs</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nn">~/.cache/pypoetry/virtualenvs/mat281-2021-V7B8LTfe-py3.8/lib/python3.8/site-packages/sklearn/utils/validation.py</span> in <span class="ni">inner_f</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">61</span>             <span class="n">extra_args</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_args</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span>             <span class="k">if</span> <span class="n">extra_args</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">63</span>                 <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">64</span> 
<span class="g g-Whitespace">     </span><span class="mi">65</span>             <span class="c1"># extra_args &gt; 0</span>

<span class="nn">~/.cache/pypoetry/virtualenvs/mat281-2021-V7B8LTfe-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py</span> in <span class="ni">fit</span><span class="nt">(self, X, y, groups, **fit_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">839</span>                 <span class="k">return</span> <span class="n">results</span>
<span class="g g-Whitespace">    </span><span class="mi">840</span> 
<span class="ne">--&gt; </span><span class="mi">841</span>             <span class="bp">self</span><span class="o">.</span><span class="n">_run_search</span><span class="p">(</span><span class="n">evaluate_candidates</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">842</span> 
<span class="g g-Whitespace">    </span><span class="mi">843</span>             <span class="c1"># multimetric is determined here because in the case of a callable</span>

<span class="nn">~/.cache/pypoetry/virtualenvs/mat281-2021-V7B8LTfe-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py</span> in <span class="ni">_run_search</span><span class="nt">(self, evaluate_candidates)</span>
<span class="g g-Whitespace">   </span><span class="mi">1294</span>     <span class="k">def</span> <span class="nf">_run_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">evaluate_candidates</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1295</span>         <span class="sd">&quot;&quot;&quot;Search all candidates in param_grid&quot;&quot;&quot;</span>
<span class="ne">-&gt; </span><span class="mi">1296</span>         <span class="n">evaluate_candidates</span><span class="p">(</span><span class="n">ParameterGrid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">1297</span> 
<span class="g g-Whitespace">   </span><span class="mi">1298</span> 

<span class="nn">~/.cache/pypoetry/virtualenvs/mat281-2021-V7B8LTfe-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_search.py</span> in <span class="ni">evaluate_candidates</span><span class="nt">(candidate_params, cv, more_results)</span>
<span class="g g-Whitespace">    </span><span class="mi">793</span>                               <span class="n">n_splits</span><span class="p">,</span> <span class="n">n_candidates</span><span class="p">,</span> <span class="n">n_candidates</span> <span class="o">*</span> <span class="n">n_splits</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">794</span> 
<span class="ne">--&gt; </span><span class="mi">795</span>                 <span class="n">out</span> <span class="o">=</span> <span class="n">parallel</span><span class="p">(</span><span class="n">delayed</span><span class="p">(</span><span class="n">_fit_and_score</span><span class="p">)(</span><span class="n">clone</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">796</span>                                                        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">797</span>                                                        <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="n">test</span><span class="p">,</span>

<span class="nn">~/.cache/pypoetry/virtualenvs/mat281-2021-V7B8LTfe-py3.8/lib/python3.8/site-packages/joblib/parallel.py</span> in <span class="ni">__call__</span><span class="nt">(self, iterable)</span>
<span class="g g-Whitespace">   </span><span class="mi">1052</span> 
<span class="g g-Whitespace">   </span><span class="mi">1053</span>             <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backend</span><span class="o">.</span><span class="n">retrieval_context</span><span class="p">():</span>
<span class="ne">-&gt; </span><span class="mi">1054</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">retrieve</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1055</span>             <span class="c1"># Make sure that we get a last message telling us we are done</span>
<span class="g g-Whitespace">   </span><span class="mi">1056</span>             <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_time</span>

<span class="nn">~/.cache/pypoetry/virtualenvs/mat281-2021-V7B8LTfe-py3.8/lib/python3.8/site-packages/joblib/parallel.py</span> in <span class="ni">retrieve</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">931</span>             <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">932</span>                 <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backend</span><span class="p">,</span> <span class="s1">&#39;supports_timeout&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">933</span>                     <span class="bp">self</span><span class="o">.</span><span class="n">_output</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">timeout</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">934</span>                 <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">935</span>                     <span class="bp">self</span><span class="o">.</span><span class="n">_output</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">get</span><span class="p">())</span>

<span class="nn">~/.cache/pypoetry/virtualenvs/mat281-2021-V7B8LTfe-py3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py</span> in <span class="ni">wrap_future_result</span><span class="nt">(future, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">540</span>         <span class="n">AsyncResults</span><span class="o">.</span><span class="n">get</span> <span class="kn">from</span> <span class="nn">multiprocessing.</span><span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">541</span><span class="s2">         try:</span>
<span class="ne">--&gt; </span><span class="mi">542</span><span class="s2">             return future.result(timeout=timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">543</span><span class="s2">         except CfTimeoutError as e:</span>
<span class="g g-Whitespace">    </span><span class="mi">544</span><span class="s2">             raise TimeoutError from e</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/concurrent/futures/_base.py</span> in <span class="ni">result</span><span class="nt">(self, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">437</span><span class="s2">                     return self.__get_result()</span>
<span class="g g-Whitespace">    </span><span class="mi">438</span><span class="s2"> </span>
<span class="ne">--&gt; </span><span class="mi">439</span><span class="s2">                 self._condition.wait(timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">440</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">441</span><span class="s2">                 if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/threading.py</span> in <span class="ni">wait</span><span class="nt">(self, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">300</span><span class="s2">         try:    # restore state no matter what (e.g., KeyboardInterrupt)</span>
<span class="g g-Whitespace">    </span><span class="mi">301</span><span class="s2">             if timeout is None:</span>
<span class="ne">--&gt; </span><span class="mi">302</span><span class="s2">                 waiter.acquire()</span>
<span class="g g-Whitespace">    </span><span class="mi">303</span><span class="s2">                 gotit = True</span>
<span class="g g-Whitespace">    </span><span class="mi">304</span><span class="s2">             else:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># imprimir resultados</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9329230769230769
{&#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: 6}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># utilizando el mejor modelo</span>
<span class="n">mejor_modelo</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">mejor_modelo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Precisión: </span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mejor_modelo</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_eval</span><span class="p">,</span> <span class="n">y_eval</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Precisión: 0.938
</pre></div>
</div>
</div>
</div>
<p>En este ejemplo, primero utilizamos el objeto <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> que nos permite realizar <em>grid search</em> junto con validación cruzada, luego comenzamos a ajustar el modelo con las diferentes combinaciones de los valores de los parámetros <code class="docutils literal notranslate"><span class="pre">criterion</span></code> y <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>. Finalmente imprimimos el mejor resultado de precisión y los valores de los parámetros que utilizamos para obtenerlos; por último utilizamos este mejor modelo para realizar las predicciones con los datos de <em>evaluación</em>.</p>
<p>Podemos ver que la precisión que obtuvimos con los datos de evaluación es casi idéntica a la que nos indicó <em>grid search</em>, lo que indica que el modelo <em>generaliza</em> muy bien.</p>
</div>
<div class="section" id="reduccion-de-dimensionalidad">
<h2>Reducción de dimensionalidad<a class="headerlink" href="#reduccion-de-dimensionalidad" title="Permalink to this headline">¶</a></h2>
<p>La <strong>reducción de dimensiones</strong> es frecuentemente usada como una etapa de preproceso en el entrenamiento de
sistemas, y consiste en escoger un subconjunto de
variables, de tal manera, que el espacio de características
quede óptimamente reducido de acuerdo a un criterio de
evaluación, cuyo fin es distinguir el subconjunto que
representa mejor el espacio inicial de entrenamiento.</p>
<p>Como cada característica que se incluye en el análisis,
puede incrementar el costo y el tiempo de proceso de los
sistemas, hay una fuerte motivación para diseñar e
implementar sistemas con pequeños conjuntos de
características. Sin dejar de lado, que al mismo tiempo,
hay una opuesta necesidad de incluir un conjunto
suficiente de características para lograr un alto
rendimiento.</p>
<p>La reducción de dimensionalidad se puede separar en dos tipos: <strong>Extracción de atributos</strong> y  <strong>Selección de aributos</strong>.</p>
<div class="section" id="extraccion-de-atributos">
<h3>Extracción de atributos<a class="headerlink" href="#extraccion-de-atributos" title="Permalink to this headline">¶</a></h3>
<p>La <strong>extracción de atributos</strong> comienza a partir de un conjunto inicial de datos medidos y crea valores derivados (características) destinados a ser informativos y no redundantes, lo que facilita los pasos de aprendizaje y generalización posteriores, y en algunos casos conduce a a mejores interpretaciones humanas.</p>
<p>Cuando los datos de entrada a un algoritmo son demasiado grandes para ser procesados y se sospecha que son redundantes (por ejemplo, la misma medición en pies y metros, o la repetitividad de las imágenes presentadas como píxeles), entonces se puede transformar en un conjunto reducido de características (también denominado un vector de características).</p>
<p>Estos algoritmos fueron analizados con profundidad en la sección de <strong>Análisis no supervisados - Reducción de la dimensionalidad</strong>.</p>
</div>
<div class="section" id="seleccion-de-atributos">
<h3>Selección de atributos<a class="headerlink" href="#seleccion-de-atributos" title="Permalink to this headline">¶</a></h3>
<p>Proceso por el cual seleccionamos un subconjunto de atributos (representados por cada una de las columnas en un datasetde forma tabular) que son más relevantes para la construcción del modelo predictivo sobre el que estamos trabajando.</p>
<p>El objetivo de la selección de atributos es :</p>
<ul class="simple">
<li><p>mejorar la capacidad predictiva de nuestro modelo,</p></li>
<li><p>proporcionando modelos predictivos más rápidos y eficientes,</p></li>
<li><p>proporcionar una mejor comprensión del proceso subyacente que generó los datos.</p></li>
</ul>
<p>Los métodos de selección de atributos se pueden utilizar para identificar y eliminar los atributos innecesarios, irrelevantes y redundantes que no contribuyen a la exactitud del modelo predictivo o incluso puedan disminuir su precisión.</p>
<p><strong>Algoritmos para selección de atributos</strong></p>
<p>Podemos encontrar dos clases generales de algoritmos de <a class="reference external" href="https://en.wikipedia.org/wiki/Feature_selection">selección de atributos</a>: los métodos de filtrado, y los métodos empaquetados.</p>
<ul class="simple">
<li><p><strong>Métodos de filtrado</strong>:  Estos métodos aplican una medida estadística para asignar una puntuación a cada atributo. Los atributos luego son clasificados de acuerdo a su puntuación y son, o bien seleccionados para su conservación o eliminados del conjunto de datos. Los métodos de filtrado son a menudo <a class="reference external" href="https://en.wikipedia.org/wiki/Univariate_analysis">univariantes</a> y consideran a cada atributo en forma independiente, o con respecto a la variable dependiente.</p>
<ul>
<li><p>Ejemplos : <a class="reference external" href="https://es.wikipedia.org/wiki/Prueba_%CF%87%C2%B2">prueba de Chi cuadrado</a>, <a class="reference external" href="https://es.wikipedia.org/wiki/Prueba_F_de_Fisher">prueba F de Fisher</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Information_gain_ratio">ratio de ganancia de información</a> y los <a class="reference external" href="https://es.wikipedia.org/wiki/Correlaci%C3%B3n">coeficientes de correlación</a>.</p></li>
</ul>
</li>
<li><p><strong>Métodos empaquetados</strong>: Estos métodos consideran la selección de un conjunto de atributos como un problema de búsqueda, en donde las diferentes combinaciones son evaluadas y comparadas. Para hacer estas evaluaciones se utiliza un modelo predictivo y luego se asigna una puntuación a cada combinación basada en la precisión del modelo.</p>
<ul>
<li><p>Un ejemplo de este método es el algoritmo de eliminación recursiva de atributos.</p></li>
</ul>
</li>
</ul>
<p>Un método popular en sklearn es el método <strong>SelectKBest</strong>, el cual selecciona las  características de acuerdo con las <span class="math notranslate nohighlight">\(k\)</span> puntuaciones más altas (de acuerdo al criterio escogido).</p>
<p>Para entender este conceptos, transformemos el conjunto de datos anterior a formato pandas DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Datos</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                          <span class="n">random_state</span><span class="o">=</span><span class="mi">1982</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;V</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">y</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>...</th>
      <th>V92</th>
      <th>V93</th>
      <th>V94</th>
      <th>V95</th>
      <th>V96</th>
      <th>V97</th>
      <th>V98</th>
      <th>V99</th>
      <th>V100</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.949283</td>
      <td>-1.075706</td>
      <td>-0.105733</td>
      <td>-0.000047</td>
      <td>-0.278974</td>
      <td>0.510083</td>
      <td>-0.778030</td>
      <td>-1.976158</td>
      <td>-1.201534</td>
      <td>-1.047384</td>
      <td>...</td>
      <td>-0.630209</td>
      <td>-0.331225</td>
      <td>-0.202422</td>
      <td>-1.786323</td>
      <td>1.540031</td>
      <td>1.119424</td>
      <td>0.507775</td>
      <td>-0.848286</td>
      <td>-0.027485</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.183904</td>
      <td>0.524554</td>
      <td>-1.561357</td>
      <td>-1.950628</td>
      <td>1.077846</td>
      <td>-0.598287</td>
      <td>0.153160</td>
      <td>-1.206113</td>
      <td>0.673170</td>
      <td>-0.843770</td>
      <td>...</td>
      <td>-1.015067</td>
      <td>0.319214</td>
      <td>0.240570</td>
      <td>-2.205400</td>
      <td>-0.430933</td>
      <td>-0.313175</td>
      <td>0.752012</td>
      <td>-0.070265</td>
      <td>1.390394</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.499151</td>
      <td>-0.625950</td>
      <td>2.977037</td>
      <td>0.612030</td>
      <td>-0.102034</td>
      <td>2.076814</td>
      <td>1.661343</td>
      <td>1.310895</td>
      <td>-1.115465</td>
      <td>-0.544276</td>
      <td>...</td>
      <td>0.311830</td>
      <td>-1.130865</td>
      <td>0.247865</td>
      <td>-0.499241</td>
      <td>-1.595737</td>
      <td>-0.496805</td>
      <td>-0.917257</td>
      <td>0.976909</td>
      <td>-1.518979</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.172063</td>
      <td>-0.599516</td>
      <td>0.154253</td>
      <td>-0.593797</td>
      <td>0.931374</td>
      <td>0.939714</td>
      <td>1.107241</td>
      <td>0.146723</td>
      <td>-0.446275</td>
      <td>0.095896</td>
      <td>...</td>
      <td>-1.641808</td>
      <td>-1.170021</td>
      <td>0.815094</td>
      <td>-0.722564</td>
      <td>-0.263476</td>
      <td>-0.715898</td>
      <td>1.962313</td>
      <td>1.076288</td>
      <td>-2.259682</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.396408</td>
      <td>0.876210</td>
      <td>-0.791795</td>
      <td>0.999677</td>
      <td>0.046859</td>
      <td>-0.166211</td>
      <td>-0.549437</td>
      <td>0.344644</td>
      <td>0.349981</td>
      <td>-0.207106</td>
      <td>...</td>
      <td>1.307020</td>
      <td>0.876912</td>
      <td>0.882497</td>
      <td>-0.704791</td>
      <td>-0.743942</td>
      <td>-0.075060</td>
      <td>0.622693</td>
      <td>0.751576</td>
      <td>0.907325</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 101 columns</p>
</div></div></div>
</div>
<p>Comencemos con un simple algoritmo <a class="reference external" href="https://en.wikipedia.org/wiki/Univariate_analysis">univariante</a> que aplica el método de filtrado. Para esto vamos a utilizar los objetos <code class="docutils literal notranslate"><span class="pre">SelectKBest</span></code> y <code class="docutils literal notranslate"><span class="pre">f_classif</span></code> del paquete <code class="docutils literal notranslate"><span class="pre">sklearn.feature_selection</span></code>.</p>
<p>Este algoritmo selecciona a los mejores atributos basándose en una prueba estadística <a class="reference external" href="https://en.wikipedia.org/wiki/Univariate_analysis">univariante</a>. Al objeto <code class="docutils literal notranslate"><span class="pre">SelectKBest</span></code> le pasamos la prueba estadística que vamos a a aplicar, en este caso una <a class="reference external" href="https://es.wikipedia.org/wiki/Prueba_F_de_Fisher">prueba F</a> definida por el objeto <code class="docutils literal notranslate"><span class="pre">f_classif</span></code>, junto con el número de atributos a seleccionar. El algoritmo va a aplicar la prueba a todos los atributos y va a seleccionar los que mejor resultado obtuvieron.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">f_classif</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Separamos las columnas objetivo</span>
<span class="n">x_training</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;y&#39;</span><span class="p">,],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_training</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="c1"># Aplicando el algoritmo univariante de prueba F.</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># número de atributos a seleccionar</span>
<span class="n">columnas</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x_training</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">seleccionadas</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_training</span><span class="p">,</span> <span class="n">y_training</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">catrib</span> <span class="o">=</span> <span class="n">seleccionadas</span><span class="o">.</span><span class="n">get_support</span><span class="p">()</span>
<span class="n">atributos</span> <span class="o">=</span> <span class="p">[</span><span class="n">columnas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">catrib</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()[</span><span class="mi">0</span><span class="p">])]</span>
<span class="n">atributos</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;V1&#39;,
 &#39;V42&#39;,
 &#39;V46&#39;,
 &#39;V49&#39;,
 &#39;V62&#39;,
 &#39;V64&#39;,
 &#39;V66&#39;,
 &#39;V68&#39;,
 &#39;V69&#39;,
 &#39;V75&#39;,
 &#39;V82&#39;,
 &#39;V86&#39;,
 &#39;V89&#39;,
 &#39;V98&#39;,
 &#39;V100&#39;]
</pre></div>
</div>
</div>
</div>
<p>Como podemos ver, el algoritmo nos seleccionó la cantidad de atributos que le indicamos; en este ejemplo decidimos seleccionar solo 15; obviamente, cuando armemos nuestro modelo final vamos a tomar un número mayor de atributos. Ahora se procederá a comparar los resultados de entrenar un modelo en particular con todas las variables y el subconjunto de variables seleccionadas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">metrics_classification</span> <span class="kn">import</span> <span class="n">summary_metrics</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="c1"># Entrenamiento con todas las variables </span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="c1"># split dataset</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> 

<span class="c1"># Creando el modelo</span>
<span class="n">rlog</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">rlog</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span> <span class="c1"># ajustando el modelo</span>

<span class="n">predicciones</span> <span class="o">=</span> <span class="n">rlog</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">df_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;y&#39;</span><span class="p">:</span><span class="n">Y_test</span><span class="p">,</span>
    <span class="s1">&#39;yhat&#39;</span><span class="p">:</span><span class="n">predicciones</span>
<span class="p">})</span>

<span class="n">df_s1</span> <span class="o">=</span> <span class="n">summary_metrics</span><span class="p">(</span><span class="n">df_pred</span><span class="p">)</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Todas las variables&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>82.4 ms ± 6.51 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>it
<span class="c1"># Entrenamiento con las variables seleccionadas</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">atributos</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="c1"># split dataset</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> 

<span class="c1"># Creando el modelo</span>
<span class="n">rlog</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">rlog</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span> <span class="c1"># ajustando el modelo</span>

<span class="n">predicciones</span> <span class="o">=</span> <span class="n">rlog</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">df_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;y&#39;</span><span class="p">:</span><span class="n">Y_test</span><span class="p">,</span>
    <span class="s1">&#39;yhat&#39;</span><span class="p">:</span><span class="n">predicciones</span>
<span class="p">})</span>

<span class="n">df_s2</span> <span class="o">=</span> <span class="n">summary_metrics</span><span class="p">(</span><span class="n">df_pred</span><span class="p">)</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Variables Seleccionadas&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>60.4 ms ± 8.62 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
</pre></div>
</div>
</div>
</div>
<p>Juntando ambos resultados:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># juntar resultados en formato dataframe</span>
<span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_s1</span><span class="p">,</span><span class="n">df_s2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>accuracy</th>
      <th>recall</th>
      <th>precision</th>
      <th>fscore</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.8905</td>
      <td>0.8906</td>
      <td>0.8907</td>
      <td>0.8905</td>
      <td>Todas las variables</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.8985</td>
      <td>0.8986</td>
      <td>0.8986</td>
      <td>0.8985</td>
      <td>Variables Seleccionadas</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Las métricas para ambos casos son parecidas y el tiempo de ejecución del modelo con menos variable resulta ser menor (lo cual era algo esperable). Lo cual nos muestra que trabajando con menos variables, se puede captar las características más relevante del problema, y en la medida que se trabaje con más datos, las mejoras a nivel de capacidad de cómputo tendrán un mejor desempeño.</p>
</div>
</div>
<div class="section" id="referencia">
<h2>Referencia<a class="headerlink" href="#referencia" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p><a class="reference external" href="https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833">K-Fold Cross Validation</a></p></li>
<li><p><a class="reference external" href="https://stackabuse.com/cross-validation-and-grid-search-for-model-selection-in-python/">Cross Validation and Grid Search for Model Selection in Python</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/jepsds/feature-selection-using-selectkbest?utm_campaign=News&amp;utm_medium=Community&amp;utm_source=DataCamp.com">Feature selection for supervised models using SelectKBest</a></p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./mat281/lectures/ml/overfitting"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="04_overfitting_underfitting.html" title="previous page">Overfitting</a>
    <a class='right-next' id="next-link" href="../time_series/05_series_temporales.html" title="next page">Series Temporales</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Francisco Alfaro Medina<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-177357392-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>