
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Clustering &#8212; Aplicaciones de la Matematica en la Ingenieria</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="shortcut icon" href="../../../../_static/logo_python.jpeg"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Reducci√≥n de dimensionalidad" href="03_reduccion_dimensionalidad.html" />
    <link rel="prev" title="Aprendizaje no supervisado" href="../introduccion_ml/no_supervisados.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
      <img src="../../../../_static/logo_python.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Aplicaciones de la Matematica en la Ingenieria</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../index.html">
   Home
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Herramientas B√°sicas
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../basic_tools/lecture_000_intro.html">
   Introducci√≥n
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basic_tools/lecture_000_configuraciones.html">
     Configuraciones
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_011_os.html">
   Linux
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_015_git.html">
   Git
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_013_ide.html">
   IDE‚Äôs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_016_venv.html">
   Virtual Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_012_python.html">
   Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_014_jupyter.html">
   Jupyter
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Computaci√≥n cientifica
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/scientific_computing/numpy.html">
   Numpy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/scientific_computing/scipy.html">
   SciPy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/scientific_computing/sympy.html">
   Sympy
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Manipulaci√≥n de datos
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/data_manipulation/base_datos.html">
   Base de datos
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data_manipulation/data_manipulation/pandas/pandas.html">
   Pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/data_manipulation/modulos_pandas/groupby.html">
     Groupby
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/data_manipulation/modulos_pandas/merge_concat.html">
     Merge &amp; Concat
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/data_manipulation/modulos_pandas/pivot.html">
     Pivot
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/data_manipulation/sqlalchemy/sqlalchemy.html">
   SQLAlchemy
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Visualizaci√≥n
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/introduction.html">
   Introducci√≥n
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/imperativa.html">
   Visualizaci√≥n Imperativa
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/matplotlib.html">
     Matplotlib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/declarativa.html">
   Visualizaci√≥n Declarativa
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/seaborn.html">
     Seaborn
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  An√°lisis exploratorio de datos
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/eda/intro.html">
   Introducci√≥n
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/eda/eda.html">
   Caso Aplicado
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduccion_ml/introduccion.html">
   Introducci√≥n
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../analisis_supervisado_regresion/intro.html">
   Aprendizaje supervisado - Regresi√≥n
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis_supervisado_regresion/02_regresion_lineal.html">
     Modelos de regressi√≥n lineal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis_supervisado_regresion/02_modelos_regresion.html">
     Modelos de regressi√≥n multiple
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../analisis_supervisado_clasificacion/intro.html">
   Aprendizaje supervisado - Clasificaci√≥n
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis_supervisado_clasificacion/02_clasificacion.html">
     Modelo de regresi√≥n log√≠stica
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../introduccion_ml/no_supervisados.html">
   Aprendizaje no supervisado
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_reduccion_dimensionalidad.html">
     Reducci√≥n de dimensionalidad
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../overfitting/04_overfitting_underfitting.html">
   Overfitting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../overfitting/04_reducir_overfitting.html">
     Reducir el overfitting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../time_series/05_series_temporales.html">
   Series Temporales
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../../_sources/mat281/lectures/ml/analisis_no_supervisado/03_clustering.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://gitlab.com/FAAM/mat281_2021"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-means">
   K-means
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#teoria">
     Teor√≠a
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algoritmo">
     Algoritmo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ventajas-y-desventajas">
     Ventajas y desventajas
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aplicacion">
     Aplicaci√≥n
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#regla-del-codo">
       Regla del codo
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hierarchical-clustering">
   Hierarchical clustering
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Teor√≠a
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Algoritmo
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#aglomerativo">
       Aglomerativo
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#divisivo">
       Divisivo
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dendograma">
     Dendograma
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Aplicaci√≥n
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#density-based-clustering-dbscan">
   Density based clustering (DBSCAN)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Teor√≠a
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     Algoritmo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hiperparametros">
     Hiperpar√°metros
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       Ventajas y desventajas
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     Aplicaci√≥n
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-mixture-models-gmms">
   Gaussian mixture models (GMMs)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     Teor√≠a
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     Algoritmo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     Aplicaci√≥n
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#limitaciones-del-clustering">
   Limitaciones del clustering
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#referencias">
   Referencias
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="clustering">
<h1>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¬∂</a></h1>
<p>El <strong>Clustering</strong> es la tarea de agrupar objetos por similitud, en grupos o conjuntos de manera que los miembros del mismo grupo tengan caracter√≠sticas similares. Es la tarea principal de la miner√≠a de datos exploratoria y es una t√©cnica com√∫n en el an√°lisis de datos estad√≠sticos.</p>
<a class="reference internal image-reference" href="../../../../_images/clust.png"><img alt="../../../../_images/clust.png" class="align-center" src="../../../../_images/clust.png" style="width: 480px; height: 300px;" /></a>
<div class="section" id="k-means">
<h2>K-means<a class="headerlink" href="#k-means" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="teoria">
<h3>Teor√≠a<a class="headerlink" href="#teoria" title="Permalink to this headline">¬∂</a></h3>
<p>El algoritmo <a class="reference external" href="https://es.wikipedia.org/wiki/K-means">K-means</a>  (MacQueen, 1967) agrupa las observaciones en un n√∫mero predefinido de <span class="math notranslate nohighlight">\(k\)</span> clusters de forma que, la suma de las varianzas internas de los clusters, sea lo menor posible.</p>
<p>Existen varias implementaciones de este algoritmo, la m√°s com√∫n de ellas se conoce como Lloyd‚Äôs. En la bibliograf√≠a es com√∫n encontrar los t√©rminos inertia, within-cluster sum-of-squares o varianza intra-cluster para referirse a la varianza interna de los clusters.</p>
<p>Consid√©rense  <span class="math notranslate nohighlight">\(ùê∂_1 ,...,  ùê∂_k\)</span>  como los sets formados por los √≠ndices de las observaciones de cada uno de los clusters. Por ejemplo, el set  <span class="math notranslate nohighlight">\(ùê∂_1\)</span>  contiene los √≠ndices de las observaciones agrupadas en el cluster 1. La nomenclatura empleada para indicar que la observaci√≥n  <span class="math notranslate nohighlight">\(i\)</span> pertenece al cluster  <span class="math notranslate nohighlight">\(k\)</span>  es:  <span class="math notranslate nohighlight">\(i \in C_k\)</span> . Todos los sets satisfacen dos propiedades:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(C_1 \cup C_2 \cup ... \cup C_k = {1,...,n} \)</span> . Significa que toda observaci√≥n pertenece a uno de los <span class="math notranslate nohighlight">\(k\)</span> clusters.</p></li>
<li><p><span class="math notranslate nohighlight">\(C_i \cap C_{j} = \emptyset \)</span>   para todo <span class="math notranslate nohighlight">\(i \neq j\)</span>   . Implica que los clusters no solapan, ninguna observaci√≥n pertenece a m√°s de un cluster a la vez.</p></li>
</ul>
<p>El algoritmo consiste en reducir al m√≠nimo la suma de las distancias cuadradas desde la media dentro del agrupamiento. Matem√°ticamente:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
(P) \ \textrm{Minimizar } f(C_l,\mu_l) = \sum_{l=1}^k \sum_{x_n \in C_l} ||x_n - \mu_l ||^2 \textrm{, respecto a } C_l, \mu_l,
\end{align*}\]</div>
<p>donde <span class="math notranslate nohighlight">\(C_l\)</span> es el cluster l-√©simo y <span class="math notranslate nohighlight">\(\mu_l\)</span> es el centroide l-√©simo.</p>
<a class="reference internal image-reference" href="../../../../_images/kmean_01.png"><img alt="../../../../_images/kmean_01.png" class="align-center" src="../../../../_images/kmean_01.png" style="width: 480px; height: 300px;" /></a>
</div>
<div class="section" id="algoritmo">
<h3>Algoritmo<a class="headerlink" href="#algoritmo" title="Permalink to this headline">¬∂</a></h3>
<ol class="simple">
<li><p>Especificar el n√∫mero <span class="math notranslate nohighlight">\(k\)</span> de clusters que se quieren crear.</p></li>
<li><p>Seleccionar de forma aleatoria <span class="math notranslate nohighlight">\(k\)</span> observaciones del set de datos como centroides iniciales.</p></li>
<li><p>Asignar cada una de las observaciones al centroide m√°s cercano.</p></li>
<li><p>Para cada uno de los <span class="math notranslate nohighlight">\(k\)</span> clusters generados en el paso 3, recalcular su centroide.</p></li>
</ol>
<p>Repetir los pasos 3 y 4 hasta que las asignaciones no cambien o se alcance el n√∫mero m√°ximo de iteraciones establecido.</p>
<p>El problema anterior es NP-hard (imposible de resolver en tiempo polinomial, del tipo m√°s dif√≠cil de los probleams NP).</p>
</div>
<div class="section" id="ventajas-y-desventajas">
<h3>Ventajas y desventajas<a class="headerlink" href="#ventajas-y-desventajas" title="Permalink to this headline">¬∂</a></h3>
<p>K-means es uno de los m√©todos de clustering m√°s utilizados. Destaca por la sencillez y velocidad de su algoritmo, sin embargo, presenta una serie de limitaciones que se deben tener en cuenta.</p>
<ul class="simple">
<li><p>Requiere que se indique de antemano el n√∫mero de clusters que se van a crear. Esto puede ser complicado si no se dispone de informaci√≥n adicional sobre los datos con los que se trabaja. Se han desarrollado varias estrategias para ayudar a identificar potenciales valores √≥ptimos de <span class="math notranslate nohighlight">\(k\)</span> (elbow, shilouette), pero todas ellas son orientativas.</p></li>
<li><p>Dificultad para detectar clusters alargados o con formas irregulares.</p></li>
<li><p>Las agrupaciones resultantes pueden variar dependiendo de la asignaci√≥n aleatoria inicial de los centroides. Para minimizar este problema, se recomienda repetir el proceso de clustering entre 25-50 veces y seleccionar como resultado definitivo el que tenga menor suma total de varianza interna. Aun as√≠, solo se puede garantizar la reproducibilidad de los resultados si se emplean semillas.</p></li>
<li><p>Presenta problemas de robustez frente a outliers.</p></li>
</ul>
</div>
<div class="section" id="aplicacion">
<h3>Aplicaci√≥n<a class="headerlink" href="#aplicacion" title="Permalink to this headline">¬∂</a></h3>
<p>Veamos un ejemplo de an√°lisis no supervisado ocupando el algoritmo <strong>k-means</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># librerias</span>
 
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span> 

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>  <span class="c1"># Ver m√°s columnas de los dataframes</span>

<span class="c1"># Ver gr√°ficos de matplotlib en jupyter notebook/lab</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">init_blobs</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
                      <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.60</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="c1"># generar datos</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">init_blobs</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">43</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">])</span>



<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-6.953617</td>
      <td>-4.989933</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-2.681117</td>
      <td>7.583914</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.510161</td>
      <td>4.933676</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-9.748491</td>
      <td>5.479457</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-7.438017</td>
      <td>-4.597754</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Debido a que trabajamos con el concepto de distancia, muchas veces las columnas del dataframe pueden estar en distintas escalas, lo cual puede complicar a los algoritmos ocupados (al menos con <strong>sklearn</strong>).</p>
<p>En estos casos, se suele <strong>normalizar</strong> los atributos, es decir, dejar los valores en una escala acotada y/o con estimadores fijos. Por ejemplo, en *<strong>sklearn</strong> podemos encontrar las siguientes formas de normalizar:</p>
<ul class="simple">
<li><p><strong>StandardScaler</strong>: se normaliza  restando la media y escalando por su desviaci√≥n estanda.
$<span class="math notranslate nohighlight">\(x_{prep} = \dfrac{x-u}{s}\)</span>$</p></li>
</ul>
<p>La ventaja es que la media del nuevo conjunto de datos cumple con la propiedad que su media <span class="math notranslate nohighlight">\(\mu\)</span> es igual a cero y su desviaci√≥n estandar <span class="math notranslate nohighlight">\(s\)</span> es igual a 1.</p>
<ul class="simple">
<li><p><strong>MinMaxScaler</strong>:  se normaliza ocupando los valores de los m√≠nimos y m√°ximo del conjunto de datos.
$<span class="math notranslate nohighlight">\(x_{prep} = \dfrac{x-x_{min}}{x_{min}-x_{max}}\)</span>$</p></li>
</ul>
<p>Esta forma de normalizar resulta √∫til cuando la desviaci√≥n estandar <span class="math notranslate nohighlight">\(s\)</span> es muy peque√±a (cercana) a cero, por lo que lo convierte en un estimador m√°s roubusto que el <strong>StandardScaler</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">])</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.579033</td>
      <td>-1.831435</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.408821</td>
      <td>1.194578</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.679560</td>
      <td>0.556774</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.225241</td>
      <td>0.688121</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.691032</td>
      <td>-1.737053</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># comprobar resultados del estimador</span>
<span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1.000000e+04</td>
      <td>1.000000e+04</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.060574e-16</td>
      <td>-2.285105e-15</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.000050e+00</td>
      <td>1.000050e+00</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-1.638247e+00</td>
      <td>-2.410317e+00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-8.015576e-01</td>
      <td>-4.418042e-01</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-2.089351e-01</td>
      <td>1.863259e-01</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>5.480066e-01</td>
      <td>8.159808e-01</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2.243358e+00</td>
      <td>1.639547e+00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Con esta parametrizaci√≥n procedemos a graficar nuestros resultados:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar </span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mf">11.7</span><span class="p">,</span><span class="mf">8.27</span><span class="p">)})</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_12_0.png" src="../../../../_images/03_clustering_12_0.png" />
</div>
</div>
<p>Ahora ajustamos el algoritmo <strong>KMeans</strong> de <strong>sklearn</strong>. Primero, comprendamos los hiperpar√°metros m√°s importantes:</p>
<ul class="simple">
<li><p><strong>n_clusters</strong>: El n√∫mero de clusters a crear, o sea <strong>K</strong>. Por defecto es 8</p></li>
<li><p><strong>init</strong>: M√©todo de inicializaci√≥n. Un problema que tiene el algoritmo K-Medias es que la solucci√≥n alcanzada varia seg√∫n la inicializaci√≥n de los centroides. <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> empieza usando el m√©todo <code class="docutils literal notranslate"><span class="pre">kmeans++</span></code> que es una versi√≥n m√°s moderna y que proporciona mejores resultados que la inicializaci√≥n aleatoria (random)</p></li>
<li><p><strong>n_init</strong>: El n√∫mero de inicializaciones a probar. B√°sicamente <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> aplica el algoritmo <code class="docutils literal notranslate"><span class="pre">n_init</span></code> veces y elige los clusters que minimizan la inercia.</p></li>
<li><p><strong>max_iter</strong>: M√°ximo n√∫mero de iteraciones para llegar al criterio de parada.</p></li>
<li><p><strong>random_state</strong>: semilla para garantizar la reproducibilidad de los resultados.</p></li>
<li><p><strong>tol</strong>: Tolerancia para declarar criterio de parada (cuanto m√°s grande, antes parar√° el algoritmo).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ajustar modelo: k-means</span>

<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="n">n_init</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="n">centroids</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span> <span class="c1"># centros </span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span> <span class="c1"># clusters</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># etiquetar los datos con los clusters encontrados</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clusters</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>
<span class="n">centroids_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">centroids</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="n">centroids_df</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar los datos etiquetados con k-means</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mf">8.5</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
                     <span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span>
                     <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span>
                     <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;cluster&quot;</span><span class="p">,</span>
                     <span class="n">legend</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span>
                     <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;Set2&quot;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span>
                     <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">centroids_df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/runner/.cache/pypoetry/virtualenvs/mat281-2021-V7B8LTfe-py3.8/lib/python3.8/site-packages/seaborn/relational.py:651: UserWarning: You passed a edgecolor/edgecolors (&#39;w&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
  points = ax.scatter(*args, **kws)
</pre></div>
</div>
<img alt="../../../../_images/03_clustering_16_1.png" src="../../../../_images/03_clustering_16_1.png" />
</div>
</div>
<p>Ahora la pregunta que surge de manera natural es ‚Ä¶ ¬ø c√≥mo escoger el mejor n√∫mero de clusters?.</p>
<p>No existe un criterio objetivo ni ampliamente v√°lido para la  elecci√≥n de un n√∫mero √≥ptimo de clusters. Aunque no exista un criterio objetivo para la selecci√≥n del n√∫mero de clusters, si que se han implementado diferentes m√©todos que nos ayudan a elegir un n√∫mero apropiado de clusters para agrupar los datos; como son,</p>
<ul class="simple">
<li><p>m√©todo del codo (elbow method)</p></li>
<li><p>criterio de Calinsky</p></li>
<li><p>Affinity Propagation (AP)</p></li>
<li><p>Gap (tambi√©n con su versi√≥n estad√≠stica)</p></li>
<li><p>Dendrogramas</p></li>
<li><p>etc.</p></li>
</ul>
<div class="section" id="regla-del-codo">
<h4>Regla del codo<a class="headerlink" href="#regla-del-codo" title="Permalink to this headline">¬∂</a></h4>
<p>Este m√©todo utiliza los valores de la funci√≥n de perdida, <span class="math notranslate nohighlight">\(f(C_l,\mu_l)\)</span>, obtenidos tras aplicar el <span class="math notranslate nohighlight">\(K\)</span>-means a diferente n√∫mero de Clusters (desde 1 a <span class="math notranslate nohighlight">\(N\)</span> clusters).</p>
<p>Una vez obtenidos los valores de la funci√≥n de p√©rdida  tras aplicar el K-means de 1 a <span class="math notranslate nohighlight">\(N\)</span> clusters, representamos en una gr√°fica lineal la funci√≥n de p√©rdida  respecto del n√∫mero de clusters.</p>
<p>En esta gr√°fica se deber√≠a de apreciar un cambio brusco en la evoluci√≥n de la funci√≥n de p√©rdida, teniendo la l√≠nea representada una forma similar a la de un brazo y su codo.</p>
<p>El punto en el que se observa ese cambio brusco en la funci√≥n de p√©rdida nos dir√° el n√∫mero √≥ptimo de clusters a seleccionar para ese data set; o dicho de otra manera: el punto que representar√≠a al codo del brazo ser√° el n√∫mero √≥ptimo de clusters para ese data set
.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># implementaci√≥n de la regla del codo</span>
<span class="n">Nc</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="p">[</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">Nc</span><span class="p">]</span>
<span class="n">score</span> <span class="o">=</span> <span class="p">[</span><span class="n">kmeans</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">inertia_</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">kmeans</span><span class="p">))]</span>


<span class="n">df_Elbow</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Number of Clusters&#39;</span><span class="p">:</span><span class="n">Nc</span><span class="p">,</span>
                        <span class="s1">&#39;Score&#39;</span><span class="p">:</span><span class="n">score</span><span class="p">})</span>

<span class="n">df_Elbow</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Number of Clusters</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>49337.951600</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>20004.858535</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>12733.014667</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>6760.679396</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>3139.657771</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar los datos etiquetados con k-means</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mf">8.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Elbow Curve&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Number of Clusters&quot;</span><span class="p">,</span>
             <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Score&quot;</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">df_Elbow</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Number of Clusters&quot;</span><span class="p">,</span>
             <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Score&quot;</span><span class="p">,</span>
             <span class="n">data</span><span class="o">=</span><span class="n">df_Elbow</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_19_0.png" src="../../../../_images/03_clustering_19_0.png" />
</div>
</div>
<p>A partir de 4 clusters la reducci√≥n en la suma total de cuadrados internos parece estabilizarse, indicando que <span class="math notranslate nohighlight">\(k\)</span> = 4 es una buena opci√≥n.</p>
</div>
</div>
</div>
<div class="section" id="hierarchical-clustering">
<h2>Hierarchical clustering<a class="headerlink" href="#hierarchical-clustering" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="id1">
<h3>Teor√≠a<a class="headerlink" href="#id1" title="Permalink to this headline">¬∂</a></h3>
<p>Hierarchical clustering es una alternativa a los m√©todos de partitioning clustering que no requiere que se pre-especifique el n√∫mero de clusters. Los m√©todos que engloba el hierarchical clustering se subdividen en dos tipos dependiendo de la estrategia seguida para crear los grupos:</p>
<ul class="simple">
<li><p><strong>Aglomerativo</strong> (agglomerative clustering o bottom-up): el agrupamiento se inicia con todas las observaciones separadas, cada una formando un cluster individual. Los clusters se van combinado a medida que la estructura crece hasta converger en uno solo.</p></li>
<li><p><strong>Divisivo</strong> (divisive clustering o top-down): es la estrategia opuesta al aglomerativo. Se inicia con todas las observaciones contenidas en un mismo cluster y se suceden divisiones hasta que cada observaci√≥n forma un cluster* individual.</p></li>
</ul>
<p>En ambos casos, los resultados pueden representarse de forma muy intuitiva en una estructura de √°rbol llamada dendrograma.</p>
</div>
<div class="section" id="id2">
<h3>Algoritmo<a class="headerlink" href="#id2" title="Permalink to this headline">¬∂</a></h3>
<div class="section" id="aglomerativo">
<h4>Aglomerativo<a class="headerlink" href="#aglomerativo" title="Permalink to this headline">¬∂</a></h4>
<p>El algoritmo seguido para por el clustering aglomerativo es:</p>
<ol class="simple">
<li><p>Considerar cada una de las n observaciones como un cluster individual, formando as√≠ la base del dendrograma (hojas).</p></li>
<li><p>Proceso iterativo hasta que todas las observaciones pertenecen a un √∫nico cluster:</p>
<ul class="simple">
<li><p>Calcular la distancia entre cada posible par de los n clusters. El investigador debe determinar el tipo de medida empleada para cuantificar la similitud entre observaciones o grupos (distancia y linkage).</p></li>
<li><p>Los dos clusters m√°s similares se fusionan, de forma que quedan n-1 clusters.</p></li>
</ul>
</li>
<li><p>Cortar la estructura de √°rbol generada (dendrograma) a una determinada altura para crear los clusters finales.</p></li>
</ol>
<p>Para que el proceso de agrupamiento pueda llevarse a cabo tal como indica el algoritmo anterior, es necesario definir c√≥mo se cuantifica la similitud entre dos clusters. Es decir, se tiene que extender el concepto de distancia entre pares de observaciones para que sea aplicable a pares de grupos, cada uno formado por varias observaciones. A este proceso se le conoce como linkage. A continuaci√≥n, se describen los 5 tipos de linkage m√°s empleados y sus definiciones.</p>
<ul class="simple">
<li><p><strong>Complete or Maximum</strong>: se calcula la distancia entre todos los posibles pares formados por una observaci√≥n del cluster A y una del cluster B. La mayor de todas ellas se selecciona como la distancia entre los dos clusters. Se trata de la medida m√°s conservadora (maximal intercluster dissimilarity).</p></li>
<li><p><strong>Single or Minimum</strong>: se calcula la distancia entre todos los posibles pares formados por una observaci√≥n del cluster A y una del cluster B. La menor de todas ellas se selecciona como la distancia entre los dos clusters. Se trata de la medida menos conservadora (minimal intercluster dissimilarity).</p></li>
<li><p><strong>Average</strong>: Se calcula la distancia entre todos los posibles pares formados por una observaci√≥n del cluster A y una del cluster B. El valor promedio de todas ellas se selecciona como la distancia entre los dos clusters (mean intercluster dissimilarity).</p></li>
<li><p><strong>Centroid</strong>: Se calcula el centroide de cada uno de los clusters y se selecciona la distancia entre ellos como la distancia entre los dos clusters.</p></li>
<li><p><strong>Ward</strong>: Se trata de un m√©todo general. La selecci√≥n del par de clusters que se combinan en cada paso del agglomerative hierarchical clustering se basa en el valor √≥ptimo de una funci√≥n objetivo, pudiendo ser esta √∫ltima cualquier funci√≥n definida por el analista. El m√©todo Ward‚Äôs minimum variance es un caso particular en el que el objetivo es minimizar la suma total de varianza intra-cluster. En cada paso, se identifican aquellos 2 clusters cuya fusi√≥n conlleva menor incremento de la varianza total intra-cluster. Esta es la misma m√©trica que se minimiza en K-means.</p></li>
</ul>
<p>Los m√©todos de complete, average y Ward‚Äôs minimum variance suelen ser los preferidos por los analistas debido a que generan dendrogramas m√°s compensados. Sin embargo, no se puede determinar que uno sea mejor que otro, ya que depende del caso de estudio en cuesti√≥n. Por ejemplo, en gen√≥mica, se emplea con frecuencia el m√©todo de centroides. Junto con los resultados de un proceso de hierarchical clustering siempre hay que indicar qu√© distancia se ha empleado, as√≠ como el tipo de linkage, ya que, dependiendo de estos, los resultados pueden variar en gran medida.</p>
</div>
<div class="section" id="divisivo">
<h4>Divisivo<a class="headerlink" href="#divisivo" title="Permalink to this headline">¬∂</a></h4>
<p>El algoritmo m√°s conocido de divisive hierarchical clustering es DIANA (DIvisive ANAlysis Clustering). Este algoritmo se inicia con un √∫nico cluster que contiene todas las observaciones. A continuaci√≥n, se van sucediendo divisiones hasta que cada observaci√≥n forma un cluster independiente. En cada iteraci√≥n, se selecciona el cluster con mayor di√°metro, entendiendo por di√°metro de un cluster la mayor de las diferencias entre dos de sus observaciones. Una vez seleccionado el cluster, se identifica la observaci√≥n m√°s dispar, que es aquella con mayor distancia promedio respecto al resto de observaciones que forman el cluster. Esta observaci√≥n inicia el nuevo cluster. Se reasignan las observaciones en funci√≥n de si est√°n m√°s pr√≥ximas al nuevo cluster o al resto de la partici√≥n, dividiendo as√≠ el cluster seleccionado en dos nuevos clusters.</p>
<ol class="simple">
<li><p>Todas las <span class="math notranslate nohighlight">\(n\)</span> observaciones forman un √∫nico cluster.</p></li>
<li><p>Repetir hasta que haya <span class="math notranslate nohighlight">\(n\)</span> clusters:</p>
<ul class="simple">
<li><p>Calcular para cada cluster la mayor de las distancias entre pares de observaciones (di√°metro del cluster).</p></li>
<li><p>Seleccionar el cluster con mayor di√°metro.</p></li>
<li><p>Calcular la distancia media de cada observaci√≥n respecto a las dem√°s.</p></li>
<li><p>La observaci√≥n m√°s distante inicia un nuevo cluster.</p></li>
<li><p>Se reasignan las observaciones restantes al nuevo cluster o al viejo dependiendo de cu√°l est√° m√°s pr√≥ximo.</p></li>
</ul>
</li>
</ol>
<p>A diferencia del clustering aglomerativo, en el que hay que elegir un tipo de distancia y un m√©todo de linkage, en el clustering divisivo solo hay que elegir la distancia, no hay linkage.</p>
</div>
</div>
<div class="section" id="dendograma">
<h3>Dendograma<a class="headerlink" href="#dendograma" title="Permalink to this headline">¬∂</a></h3>
<p>Los resultados del hierarchical clustering pueden representarse como un √°rbol en el que las ramas representan la jerarqu√≠a con la que se van sucediendo las uniones de clusters.</p>
<p>Sup√≥ngase que se dispone de 45 observaciones en un espacio de dos dimensiones, a los que se les aplica hierarchical clustering para intentar identificar grupos. El siguiente dendrograma representa los resultados obtenidos.</p>
<img alt="../../../../_images/hc_01.png" class="align-center" src="../../../../_images/hc_01.png" />
<p>En la base del dendrograma, cada observaci√≥n forma una terminaci√≥n individual conocida como hoja o leaf del √°rbol. A medida que se asciende por la estructura, pares de hojas se fusionan formando las primeras ramas. Estas uniones se corresponden con los pares de observaciones m√°s similares. Tambi√©n ocurre que las ramas se fusionan con otras ramas o con hojas. Cuanto m√°s temprana (m√°s pr√≥xima a la base del dendrograma) ocurre una fusi√≥n, mayor es la similitud.</p>
<p>Para cualquier par de observaciones, se puede identificar el punto del √°rbol en el que las ramas que contienen dichas observaciones se fusionan. La altura a la que esto ocurre (eje vertical) indica c√≥mo de similares/diferentes son las dos observaciones. Los dendrogramas, por lo tanto, se deben interpretar √∫nicamente en base al eje vertical y no por las posiciones que ocupan las observaciones en el eje horizontal, esto √∫ltimo es simplemente por est√©tica y puede variar de un programa a otro.</p>
<p>Por ejemplo, la observaci√≥n 8 es la m√°s similar a la 10 ya que es la primera fusi√≥n que recibe la observaci√≥n 10 (y viceversa). Podr√≠a resultar tentador decir que la observaci√≥n 14, situada inmediatamente a la derecha de la 10, es la siguiente m√°s similar, sin embargo, las observaciones 28 y 44 son m√°s similares a la 10 a pesar de que se encuentran m√°s alejadas en el eje horizontal. Del mismo modo, no es correcto decir que la observaci√≥n 14 es m√°s similar a la observaci√≥n 10 de lo que lo es la 36 por el hecho de que est√° m√°s pr√≥xima en el eje horizontal. Prestando atenci√≥n a la altura en que las respectivas ramas se unen, la √∫nica conclusi√≥n v√°lida es que la similitud entre los pares 10-14 y 10-36 es la misma.</p>
<p><strong>Cortar el dendograma para generar los clusters</strong></p>
<p>Adem√°s de representar en un dendrograma la similitud entre observaciones, se tiene que identificar el n√∫mero de clusters creados y qu√© observaciones forman parte de cada uno. Si se realiza un corte horizontal a una determinada altura del dendrograma, el n√∫mero de ramas que sobrepasan (en sentido ascendente) dicho corte se corresponde con el n√∫mero de clusters. La siguiente imagen muestra dos veces el mismo dendrograma. Si se realiza el corte a la altura de 5, se obtienen dos clusters, mientras que si se hace a la de 3.5 se obtienen 4. La altura de corte tiene por lo tanto la misma funci√≥n que el valor K en K-means-clustering: controla el n√∫mero de clusters obtenidos.</p>
<a class="reference internal image-reference" href="../../../../_images/hc_02.png"><img alt="../../../../_images/hc_02.png" class="align-center" src="../../../../_images/hc_02.png" style="width: 600px; height: 600px;" /></a>
<a class="reference internal image-reference" href="../../../../_images/hc_03.png"><img alt="../../../../_images/hc_03.png" class="align-center" src="../../../../_images/hc_03.png" style="width: 600px; height: 600px;" /></a>
<p>Dos propiedades adicionales se derivan de la forma en que se generan los clusters en el m√©todo de hierarchical clustering:</p>
<ul class="simple">
<li><p>Dada la longitud variable de las ramas, siempre existe un intervalo de altura para el que cualquier corte da lugar al mismo n√∫mero de clusters. En el ejemplo anterior, todos los cortes entre las alturas 5 y 6 tienen como resultado los mismos 2 clusters.</p></li>
<li><p>Con un solo dendrograma se dispone de la flexibilidad para generar cualquier n√∫mero de clusters desde 1 a n. La selecci√≥n del n√∫mero √≥ptimo puede valorarse de forma visual, tratando de identificar las ramas principales en base a la altura a la que ocurren las uniones. En el ejemplo expuesto es razonable elegir entre 2 o 4 clusters.</p></li>
</ul>
</div>
<div class="section" id="id3">
<h3>Aplicaci√≥n<a class="headerlink" href="#id3" title="Permalink to this headline">¬∂</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tratamiento de datos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="c1"># Gr√°ficos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">style</span>
<span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

<span class="c1"># Preprocesado y modelado</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">dendrogram</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="c1"># Configuraci√≥n warnings</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generar datos</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span>
        <span class="n">n_samples</span>    <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> 
        <span class="n">n_features</span>   <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> 
        <span class="n">centers</span>      <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> 
        <span class="n">cluster_std</span>  <span class="o">=</span> <span class="mf">0.60</span><span class="p">,</span> 
        <span class="n">shuffle</span>      <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
        <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span>
       <span class="p">)</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;x&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
    <span class="s1">&#39;y&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="p">})</span>


<span class="c1"># Escalado de datos</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">])</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.348818</td>
      <td>-0.908114</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.638621</td>
      <td>-0.534950</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.653079</td>
      <td>0.027910</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.573023</td>
      <td>1.276049</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.970706</td>
      <td>-1.418431</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar </span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mf">11.7</span><span class="p">,</span><span class="mf">8.27</span><span class="p">)})</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_30_0.png" src="../../../../_images/03_clustering_30_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Modelos</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># primer modelo</span>
<span class="n">modelo_hclust_complete</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span>
                            <span class="n">affinity</span> <span class="o">=</span> <span class="s1">&#39;euclidean&#39;</span><span class="p">,</span>
                            <span class="n">linkage</span>  <span class="o">=</span> <span class="s1">&#39;complete&#39;</span><span class="p">,</span>
                            <span class="n">distance_threshold</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                            <span class="n">n_clusters</span>         <span class="o">=</span> <span class="kc">None</span>
                        <span class="p">)</span>
<span class="n">modelo_hclust_complete</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AgglomerativeClustering(distance_threshold=0, linkage=&#39;complete&#39;,
                        n_clusters=None)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># segundo modelo</span>
<span class="n">modelo_hclust_average</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span>
                            <span class="n">affinity</span> <span class="o">=</span> <span class="s1">&#39;euclidean&#39;</span><span class="p">,</span>
                            <span class="n">linkage</span>  <span class="o">=</span> <span class="s1">&#39;average&#39;</span><span class="p">,</span>
                            <span class="n">distance_threshold</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                            <span class="n">n_clusters</span>         <span class="o">=</span> <span class="kc">None</span>
                        <span class="p">)</span>
<span class="n">modelo_hclust_average</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AgglomerativeClustering(distance_threshold=0, linkage=&#39;average&#39;,
                        n_clusters=None)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tercer modelo</span>
<span class="n">modelo_hclust_ward</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span>
                            <span class="n">affinity</span> <span class="o">=</span> <span class="s1">&#39;euclidean&#39;</span><span class="p">,</span>
                            <span class="n">linkage</span>  <span class="o">=</span> <span class="s1">&#39;ward&#39;</span><span class="p">,</span>
                            <span class="n">distance_threshold</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                            <span class="n">n_clusters</span>         <span class="o">=</span> <span class="kc">None</span>
                     <span class="p">)</span>
<span class="n">modelo_hclust_ward</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AgglomerativeClustering(distance_threshold=0, n_clusters=None)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_dendrogram</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Esta funci√≥n extrae la informaci√≥n de un modelo AgglomerativeClustering</span>
<span class="sd">    y representa su dendograma con la funci√≥n dendogram de scipy.cluster.hierarchy</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">children_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">merge</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">children_</span><span class="p">):</span>
        <span class="n">current_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">child_idx</span> <span class="ow">in</span> <span class="n">merge</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">child_idx</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
                <span class="n">current_count</span> <span class="o">+=</span> <span class="mi">1</span>  <span class="c1"># leaf node</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">current_count</span> <span class="o">+=</span> <span class="n">counts</span><span class="p">[</span><span class="n">child_idx</span> <span class="o">-</span> <span class="n">n_samples</span><span class="p">]</span>
        <span class="n">counts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_count</span>

    <span class="n">linkage_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">children_</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">distances_</span><span class="p">,</span>
                                      <span class="n">counts</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

    <span class="c1"># Plot</span>
    <span class="n">dendrogram</span><span class="p">(</span><span class="n">linkage_matrix</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dendrogramas</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> 
<span class="n">plot_dendrogram</span><span class="p">(</span><span class="n">modelo_hclust_average</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distancia eucl√≠dea, Linkage average&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_36_0.png" src="../../../../_images/03_clustering_36_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dendrogramas</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> 
<span class="n">plot_dendrogram</span><span class="p">(</span><span class="n">modelo_hclust_complete</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distancia eucl√≠dea, Linkage complete&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_37_0.png" src="../../../../_images/03_clustering_37_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dendrogramas</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> 
<span class="n">plot_dendrogram</span><span class="p">(</span><span class="n">modelo_hclust_ward</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distancia eucl√≠dea, Linkage ward&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_38_0.png" src="../../../../_images/03_clustering_38_0.png" />
</div>
</div>
<p>En este caso, los tres tipos de linkage identifican claramente 4 clusters, si bien esto no significa que en los 3 dendrogramas los clusters est√©n formados por exactamente las mismas observaciones.</p>
<p><strong>N√∫mero de clusters</strong></p>
<p>Una forma de identificar el n√∫mero de clusters, es inspeccionar visualmente el dendograma y decidir a qu√© altura se corta para generar los clusters. Por ejemplo, para los resultados generados mediante distancia eucl√≠dea y linkage ward, parece sensato cortar el dendograma a una altura de entre 5 y 10, de forma que se creen 4 clusters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> 
<span class="n">altura_corte</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">plot_dendrogram</span><span class="p">(</span><span class="n">modelo_hclust_ward</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="n">altura_corte</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distancia eucl√≠dea, Linkage ward&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">altura_corte</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;altura corte&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_41_0.png" src="../../../../_images/03_clustering_41_0.png" />
</div>
</div>
<p>Una vez identificado el n√∫mero √≥ptimo de clusters, se reentrena el modelo indicando este valor.</p>
</div>
</div>
<div class="section" id="density-based-clustering-dbscan">
<h2>Density based clustering (DBSCAN)<a class="headerlink" href="#density-based-clustering-dbscan" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="id4">
<h3>Teor√≠a<a class="headerlink" href="#id4" title="Permalink to this headline">¬∂</a></h3>
<p>Density-based spatial clustering of applications with noise (DBSCAN) fue presentado en 1996 por Ester et al. como una forma de identificar clusters siguiendo el modo intuitivo en el que lo hace el cerebro humano, identificando regiones con alta densidad de observaciones separadas por regiones de baja densidad.</p>
<a class="reference internal image-reference" href="../../../../_images/dbs_01.png"><img alt="../../../../_images/dbs_01.png" class="align-center" src="../../../../_images/dbs_01.png" style="width: 480px; height: 300px;" /></a>
<p>El cerebro humano identifica f√°cilmente 5 agrupaciones y algunas observaciones aisladas (ruido). V√©anse ahora los clusters que se obtienen si se aplica, por ejemplo, K-means clustering.</p>
<a class="reference internal image-reference" href="../../../../_images/dbs_02.png"><img alt="../../../../_images/dbs_02.png" class="align-center" src="../../../../_images/dbs_02.png" style="width: 480px; height: 300px;" /></a>
<p>Los clusters generados distan mucho de representar las verdaderas agrupaciones. Esto es as√≠ porque los m√©todos de partitioning clustering como k-means, hierarchical, k-medoids, ‚Ä¶ son buenos encontrando agrupaciones con forma esf√©rica o convexa que no contengan un exceso de outliers o ruido, pero fallan al tratar de identificar formas arbitrarias. De ah√≠ que el √∫nico cluster que se corresponde con un grupo real sea el amarillo.</p>
<p>DBSCAN evita este problema siguiendo la idea de que, para que una observaci√≥n forme parte de un cluster, tiene que haber un m√≠nimo de observaciones vecinas dentro de un radio de proximidad y de que los clusters est√°n separados por regiones vac√≠as o con pocas observaciones.</p>
<p>El algoritmo DBSCAN necesita dos par√°metros:</p>
<ul class="simple">
<li><p>Epsilon  (<span class="math notranslate nohighlight">\(\epsilon\)</span>) : radio que define la regi√≥n vecina a una observaci√≥n, tambi√©n llamada  ùúñ -neighborhood.</p></li>
<li><p>Minimum points (<span class="math notranslate nohighlight">\(min_samples\)</span>): n√∫mero m√≠nimo de observaciones dentro de la regi√≥n epsilon.</p></li>
</ul>
<p>Empleando estos dos par√°metros, cada observaci√≥n del set de datos se puede clasificar en una de las siguientes tres categor√≠as:</p>
<ul class="simple">
<li><p><strong>Core point</strong>: observaci√≥n que tiene en su  ùúñ -neighborhood un n√∫mero de observaciones vecinas igual o mayor a min_samples.</p></li>
<li><p><strong>Border point</strong>: observaci√≥n no satisface el m√≠nimo de observaciones vecinas para ser core point pero que pertenece al  <span class="math notranslate nohighlight">\(\epsilon\)</span>-neighborhood de otra observaci√≥n que s√≠ es core point.</p></li>
<li><p><strong>Noise-outlier</strong>: observaci√≥n que no es core point ni border point.</p></li>
</ul>
<p>Por √∫ltimo, empleando las tres categor√≠as anteriores se pueden definir tres niveles de conectividad entre observaciones:</p>
<ul class="simple">
<li><p>Directamente alcanzable (direct density reachable): una observaci√≥n  <span class="math notranslate nohighlight">\(A\)</span>  es directamente alcanzable desde otra observaci√≥n  <span class="math notranslate nohighlight">\(B\)</span>  si  <span class="math notranslate nohighlight">\(A\)</span>  forma parte del  <span class="math notranslate nohighlight">\(\epsilon\)</span> -neighborhood de  <span class="math notranslate nohighlight">\(B\)</span>  y  <span class="math notranslate nohighlight">\(B\)</span>  es un core point. Por definici√≥n, las observaciones solo pueden ser directamente alcanzables desde un core point.</p></li>
<li><p>Alcanzable (density reachable): una observaci√≥n  <span class="math notranslate nohighlight">\(A\)</span>  es alcanzable desde otra observaci√≥n  <span class="math notranslate nohighlight">\(ùêµ\)</span>  si existe una secuencia de core points que van desde  <span class="math notranslate nohighlight">\(B\)</span>  a  <span class="math notranslate nohighlight">\(A\)</span> .</p></li>
<li><p>Densamente conectadas (density conected): dos observaciones <span class="math notranslate nohighlight">\(A\)</span>  y  <span class="math notranslate nohighlight">\(B\)</span>  est√°n densamente conectadas si existe una observaci√≥n core point  <span class="math notranslate nohighlight">\(C\)</span>  tal que  <span class="math notranslate nohighlight">\(A\)</span>  y  <span class="math notranslate nohighlight">\(B\)</span>  son alcanzables desde  <span class="math notranslate nohighlight">\(C\)</span> .</p></li>
</ul>
<p>La siguiente imagen muestra las conexiones existentes entre un conjunto de observaciones si se emplea  <span class="math notranslate nohighlight">\(min_samples = 4\)</span> . La observaci√≥n  <span class="math notranslate nohighlight">\(A\)</span>  y el resto de observaciones marcadas en rojo son core points, ya que todas ellas contienen al menos 4 observaciones vecinas (incluy√©ndose a ellas mismas) en su  <span class="math notranslate nohighlight">\(\epsilon\)</span>-neighborhood. Como todas son alcanzables entre ellas, forman un cluster. Las observaciones  <span class="math notranslate nohighlight">\(B\)</span>  y  <span class="math notranslate nohighlight">\(C\)</span>  no son core points pero son alcanzables desde  <span class="math notranslate nohighlight">\(A\)</span>  a trav√©s de otros core points, por lo tanto, pertenecen al mismo cluster que  <span class="math notranslate nohighlight">\(A\)</span> . La observaci√≥n  <span class="math notranslate nohighlight">\(N\)</span>  no es ni un core point ni es directamente alcanzable, por lo que se considera como ruido.</p>
<a class="reference internal image-reference" href="../../../../_images/dbs_03.png"><img alt="../../../../_images/dbs_03.png" class="align-center" src="../../../../_images/dbs_03.png" style="width: 480px; height: 300px;" /></a>
</div>
<div class="section" id="id5">
<h3>Algoritmo<a class="headerlink" href="#id5" title="Permalink to this headline">¬∂</a></h3>
<ol class="simple">
<li><p>Para cada observaci√≥n <span class="math notranslate nohighlight">\(x_i\)</span> calcular la distancia entre ella y el resto de observaciones. Si en su  <span class="math notranslate nohighlight">\(epsilon\)</span> -neighborhood hay un n√∫mero de observaciones <span class="math notranslate nohighlight">\(\geq min_samples\)</span>  marcar la observaci√≥n como core point, de lo contrario marcarla como visitada.</p></li>
<li><p>Para cada observaci√≥n  <span class="math notranslate nohighlight">\(x_i\)</span>   marcada como core point, si todav√≠a no ha sido asignada a ning√∫n cluster, crear uno nuevo y asignarla a √©l. Encontrar recursivamente todas las observaciones densamente conectadas a ella y asignarlas al mismo cluster.</p></li>
<li><p>Iterar el mismo proceso para todas las observaciones que no hayan sido visitadas.</p></li>
<li><p>Aquellas observaciones que tras haber sido visitadas no pertenecen a ning√∫n cluster se marcan como outliers.</p></li>
</ol>
<p>Como resultado, todo cluster cumple dos propiedades: todos los puntos que forman parte de un mismo cluster est√°n densamente conectados entre ellos y, si una observaci√≥n <span class="math notranslate nohighlight">\(A\)</span>  es densamente alcanzable desde cualquier otra observaci√≥n de un cluster, entonces <span class="math notranslate nohighlight">\(A\)</span>  tambi√©n pertenece al cluster.</p>
</div>
<div class="section" id="hiperparametros">
<h3>Hiperpar√°metros<a class="headerlink" href="#hiperparametros" title="Permalink to this headline">¬∂</a></h3>
<p>Como ocurre en muchas otras t√©cnicas estad√≠sticas, en DBSCAN no existe una forma √∫nica y exacta de encontrar el valor adecuado de epsilon  (<span class="math notranslate nohighlight">\(\epsilon\)</span>))  y  <span class="math notranslate nohighlight">\(min_samples\)</span>) . A modo orientativo se pueden seguir las siguientes premisas:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(min_samples\)</span> : cuanto mayor sea el tama√±o del set de datos, mayor debe ser el valor m√≠nimo de observaciones vecinas. En el libro Practical Guide to Cluster Analysis in R recomiendan no bajar nunca de 3. Si los datos contienen niveles altos de ruido, aumentar  <span class="math notranslate nohighlight">\(min_samples\)</span>  favorecer√° la creaci√≥n de clusters significativos menos influenciados por outliers.</p></li>
<li><p>epsilon (<span class="math notranslate nohighlight">\(\epsilon\)</span>): una buena forma de escoger el valor de <span class="math notranslate nohighlight">\(\epsilon\)</span>  es estudiar las distancias promedio entre las  <span class="math notranslate nohighlight">\(k = minsamplesùë†\)</span>  observaciones m√°s pr√≥ximas. Al representar estas distancias en funci√≥n de  <span class="math notranslate nohighlight">\(\epsilon\)</span> , el punto de inflexi√≥n de la curva suele ser un valor √≥ptimo. Si el valor de  <span class="math notranslate nohighlight">\(\epsilon\)</span> escogido es muy peque√±o, una proporci√≥n alta de las observaciones no se asignar√°n a ning√∫n cluster, por el contrario, si el valor es demasiado grande, la mayor√≠a de observaciones se agrupar√°n en un √∫nico cluster.</p></li>
</ul>
<div class="section" id="id6">
<h4>Ventajas y desventajas<a class="headerlink" href="#id6" title="Permalink to this headline">¬∂</a></h4>
<ul class="simple">
<li><p>Ventajas</p>
<ul>
<li><p>No requiere que el usuario especifique el n√∫mero de clusters.</p></li>
<li><p>Es independiente de la forma que tengan los clusters.</p></li>
<li><p>Puede identificar outliers, por lo que los clusters generados no se ven influenciados por ellos.</p></li>
</ul>
</li>
<li><p>Desventajas</p>
<ul>
<li><p>Es un m√©todo determin√≠stico siempre y cuando el orden de los datos sea el mismo. Los border points que son alcanzables desde m√°s de un cluster pueden asignarse a uno u otro dependiendo del orden en el que se procesen los datos.</p></li>
<li><p>No genera buenos resultados cuando la densidad de los grupos es muy distinta, ya que no es posible encontrar los par√°metros  ùúñ  y min_samples que sirvan para todos a la vez.</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="id7">
<h3>Aplicaci√≥n<a class="headerlink" href="#id7" title="Permalink to this headline">¬∂</a></h3>
<p>Veamos un ejemplo de an√°lisis no supervisado ocupando el algoritmo <strong>DBSCAN</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tratamiento de datos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="c1"># Gr√°ficos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">style</span>
<span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

<span class="c1"># Preprocesado y modelado</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="c1"># Configuraci√≥n warnings</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/multishape.csv&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
      <th>shape</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.803739</td>
      <td>-0.853053</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.852851</td>
      <td>0.367618</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.927180</td>
      <td>-0.274902</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.752626</td>
      <td>-0.511565</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.706846</td>
      <td>0.810679</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar </span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mf">11.7</span><span class="p">,</span><span class="mf">8.27</span><span class="p">)})</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_53_0.png" src="../../../../_images/03_clustering_53_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Escalado de datos</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
      <th>shape</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.120749</td>
      <td>-0.193616</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.448907</td>
      <td>0.844692</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.564203</td>
      <td>0.298161</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.041463</td>
      <td>0.096855</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.222429</td>
      <td>1.221561</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Modelo</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]])</span>

<span class="n">modelo_dbscan</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span>
                    <span class="n">eps</span>          <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
                    <span class="n">min_samples</span>  <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                    <span class="n">metric</span>       <span class="o">=</span> <span class="s1">&#39;euclidean&#39;</span><span class="p">,</span>
                <span class="p">)</span>


<span class="n">modelo_dbscan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DBSCAN(eps=0.2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># agregar labels</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">modelo_dbscan</span><span class="o">.</span><span class="n">labels_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar </span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mf">11.7</span><span class="p">,</span><span class="mf">8.27</span><span class="p">)})</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span><span class="n">hue</span> <span class="o">=</span> <span class="s2">&quot;labels&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_57_0.png" src="../../../../_images/03_clustering_57_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># N√∫mero de clusters y observaciones &quot;outliers&quot;</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">n_noise</span>    <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;N√∫mero de clusters encontrados: </span><span class="si">{</span><span class="n">n_clusters</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;N√∫mero de outliers encontrados: </span><span class="si">{</span><span class="n">n_noise</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>N√∫mero de clusters encontrados: 6
N√∫mero de outliers encontrados: 25
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="gaussian-mixture-models-gmms">
<h2>Gaussian mixture models (GMMs)<a class="headerlink" href="#gaussian-mixture-models-gmms" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="id8">
<h3>Teor√≠a<a class="headerlink" href="#id8" title="Permalink to this headline">¬∂</a></h3>
<p>Un <a class="reference external" href="https://brilliant.org/wiki/gaussian-mixture-model/">Gaussian Mixture model</a> es un modelo probabil√≠stico en el que se considera que las observaciones siguen una distribuci√≥n probabil√≠stica formada por la combinaci√≥n de m√∫ltiples distribuciones normales (componentes). En su aplicaci√≥n al clustering, puede entenderse como una generalizaci√≥n de <em>K-means</em> con la que, en lugar de asignar cada observaci√≥n a un √∫nico cluster, se obtiene una probabilidad de pertenencia a cada uno.</p>
<p>Para estimar los par√°metros que definen la funci√≥n de distribuci√≥n de cada cluster (media y matriz de covarianza) se recurre al algoritmo de Expectation-Maximization (EM). Una vez aprendidos los par√°metros, se puede calcular la probabilidad que tiene cada observaci√≥n de pertenecer a cada cluster y asignarla a aquel con mayor probabilidad.</p>
<img alt="../../../../_images/gmm_01.png" class="align-center" src="../../../../_images/gmm_01.png" />
</div>
<div class="section" id="id9">
<h3>Algoritmo<a class="headerlink" href="#id9" title="Permalink to this headline">¬∂</a></h3>
<p>Junto con el n√∫mero de clusters (componentes), hay que determinar el tipo de matriz de covarianza que pueden tener los clusters. Dependiendo del tipo de matriz, la forma de los clusters puede ser:</p>
<ul class="simple">
<li><p>tied: todos los clusters comparten la misma matriz de covarianza.</p></li>
<li><p>diagonal: las dimensiones de cada cluster a lo largo de cada dimensi√≥n puede ser distinto, pero las elipses generadas siempre quedan alineadas con los ejes, es decir, su orientaciones son limitadas.</p></li>
<li><p>spherical: las dimensiones de cada cluster son las mismas en todas las dimensiones. Esto permite generar clusters de distinto tama√±o pero todos esf√©ricos.</p></li>
<li><p>full: cada cluster puede puede ser modelado como una elipse cualquier orientaci√≥n y dimensiones.</p></li>
</ul>
</div>
<div class="section" id="id10">
<h3>Aplicaci√≥n<a class="headerlink" href="#id10" title="Permalink to this headline">¬∂</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tratamiento de datos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="c1"># Gr√°ficos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Ellipse</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">style</span>
<span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

<span class="c1"># Preprocesado y modelado</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="c1"># Configuraci√≥n warnings</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generar datos</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span>
        <span class="n">n_samples</span>    <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> 
        <span class="n">n_features</span>   <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> 
        <span class="n">centers</span>      <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> 
        <span class="n">cluster_std</span>  <span class="o">=</span> <span class="mf">0.60</span><span class="p">,</span> 
        <span class="n">shuffle</span>      <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
        <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span>
       <span class="p">)</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;x&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
    <span class="s1">&#39;y&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="p">})</span>


<span class="c1"># Escalado de datos</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">])</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.516255</td>
      <td>-0.707227</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.861664</td>
      <td>1.329068</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.711174</td>
      <td>0.437049</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.619792</td>
      <td>1.485573</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.782282</td>
      <td>-0.801378</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar </span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mf">11.7</span><span class="p">,</span><span class="mf">8.27</span><span class="p">)})</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_62_0.png" src="../../../../_images/03_clustering_62_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Modelo</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]])</span>
<span class="n">modelo_gmm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">modelo_gmm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GaussianMixture(n_components=4, random_state=123)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Media de cada componente</span>
<span class="n">modelo_gmm</span><span class="o">.</span><span class="n">means_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 0.57844185,  0.17292982],
       [ 1.2180002 , -1.19725866],
       [-0.96910551, -0.44143927],
       [-0.83710796,  1.46219241]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Matriz de covarianza de cada componente</span>
<span class="n">modelo_gmm</span><span class="o">.</span><span class="n">covariances_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[[ 0.14277634, -0.00527707],
        [-0.00527707,  0.05201453]],

       [[ 0.12745218, -0.00619666],
        [-0.00619666,  0.05157763]],

       [[ 0.12131004,  0.00243031],
        [ 0.00243031,  0.04602115]],

       [[ 0.15451151,  0.0068188 ],
        [ 0.0068188 ,  0.05660383]]])
</pre></div>
</div>
</div>
</div>
<p><strong>Predicci√≥n y clasificaci√≥n</strong></p>
<p>Una vez entrenado el modelo GMMs, se puede predecir la probabilidad que tiene cada observaci√≥n de pertenecer a cada una de las componentes (clusters). Para obtener la clasificaci√≥n final, se asigna a la componente con mayor probabilidad</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Probabilidades</span>
<span class="c1"># ==============================================================================</span>
<span class="c1"># Cada fila es una observaci√≥n y cada columna la probabilidad de pertenecer a</span>
<span class="c1"># cada una de las componentes.</span>
<span class="n">probabilidades</span> <span class="o">=</span> <span class="n">modelo_gmm</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">probabilidades</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[2.59319058e-02, 9.71686641e-01, 2.38145325e-03, 8.05199375e-21],
       [7.16006205e-09, 7.13831446e-33, 2.34989165e-15, 9.99999993e-01],
       [9.99999970e-01, 8.78380305e-12, 9.13663813e-09, 2.04805600e-08],
       ...,
       [9.99965889e-01, 4.92493619e-10, 3.41016281e-05, 8.75675460e-09],
       [3.01319652e-06, 6.45628361e-30, 1.52897049e-18, 9.99996987e-01],
       [4.39337172e-07, 1.99785604e-11, 9.99999561e-01, 4.05381245e-15]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Clasificaci√≥n (asignaci√≥n a la componente de mayor probabilidad)</span>
<span class="c1"># ==============================================================================</span>
<span class="c1"># Cada fila es una observaci√≥n y cada columna la probabilidad de pertenecer a</span>
<span class="c1"># cada una de las componentes.</span>
<span class="n">clasificacion</span> <span class="o">=</span> <span class="n">modelo_gmm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">clasificacion</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1, 3, 0, 3, 1, 1, 2, 0, 3, 3, 2, 3, 0, 3, 1, 0, 0, 1, 2, 2, 1, 1,
       0, 2, 2, 0, 1, 0, 2, 0, 3, 3, 0, 3, 3, 3, 3, 3, 2, 1, 0, 2, 0, 0,
       2, 2, 3, 2, 3, 1, 2, 1, 3, 1, 1, 2, 3, 2, 3, 1, 3, 0, 3, 2, 2, 2,
       3, 1, 3, 2, 0, 2, 3, 2, 2, 3, 2, 0, 1, 3, 1, 0, 1, 1, 3, 0, 1, 0,
       3, 3, 0, 1, 3, 2, 2, 0, 1, 1, 0, 2, 3, 1, 3, 1, 0, 1, 1, 0, 3, 0,
       2, 2, 1, 3, 1, 0, 3, 1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 3, 2,
       2, 1, 3, 2, 2, 3, 0, 3, 3, 2, 0, 2, 0, 2, 3, 0, 3, 3, 3, 0, 3, 0,
       1, 2, 3, 2, 1, 0, 3, 0, 0, 1, 0, 2, 2, 0, 1, 0, 0, 3, 1, 0, 2, 3,
       1, 1, 0, 2, 1, 0, 2, 2, 0, 0, 0, 0, 1, 3, 0, 2, 0, 0, 2, 2, 2, 0,
       2, 3, 0, 2, 1, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 0, 3, 2, 2, 1, 1, 0,
       3, 1, 1, 2, 1, 2, 0, 3, 3, 0, 0, 3, 0, 1, 2, 0, 1, 2, 3, 2, 1, 0,
       1, 3, 3, 3, 3, 2, 2, 3, 0, 2, 1, 0, 2, 2, 2, 1, 1, 3, 0, 0, 2, 1,
       3, 2, 0, 3, 0, 1, 1, 2, 2, 0, 1, 1, 1, 0, 3, 3, 1, 1, 0, 1, 1, 1,
       3, 2, 3, 0, 1, 1, 3, 3, 3, 1, 1, 0, 3, 2])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Representaci√≥n gr√°fica</span>
<span class="c1"># ==============================================================================</span>
<span class="c1"># Codigo obtenido de:</span>
<span class="c1"># https://github.com/amueller/COMS4995-s20/tree/master/slides/aml-14-clustering-mixture-models </span>
<span class="k">def</span> <span class="nf">make_ellipses</span><span class="p">(</span><span class="n">gmm</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariance_type</span> <span class="o">==</span> <span class="s1">&#39;full&#39;</span><span class="p">:</span>
            <span class="n">covariances</span> <span class="o">=</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariances_</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariance_type</span> <span class="o">==</span> <span class="s1">&#39;tied&#39;</span><span class="p">:</span>
            <span class="n">covariances</span> <span class="o">=</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariances_</span>
        <span class="k">elif</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariance_type</span> <span class="o">==</span> <span class="s1">&#39;diag&#39;</span><span class="p">:</span>
            <span class="n">covariances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">covariances_</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariance_type</span> <span class="o">==</span> <span class="s1">&#39;spherical&#39;</span><span class="p">:</span>
            <span class="n">covariances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">means_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariances_</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
        <span class="n">v</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">covariances</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">angle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">u</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">angle</span> <span class="o">=</span> <span class="mi">180</span> <span class="o">*</span> <span class="n">angle</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>  <span class="c1"># convert to degrees</span>
        <span class="n">v</span> <span class="o">=</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">ell</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">patches</span><span class="o">.</span><span class="n">Ellipse</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">means_</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">i</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">i</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                      <span class="mi">180</span> <span class="o">+</span> <span class="n">angle</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
            <span class="n">ell</span><span class="o">.</span><span class="n">set_clip_box</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">bbox</span><span class="p">)</span>
            <span class="n">ell</span><span class="o">.</span><span class="n">set_alpha</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">ell</span><span class="p">)</span>
        
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Distribuci√≥n de probabilidad de cada componente</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">clasificacion</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">clasificacion</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">clasificacion</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
        <span class="n">c</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.prop_cycle&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">by_key</span><span class="p">()[</span><span class="s1">&#39;color&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span>
        <span class="n">marker</span>    <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span>
        <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> 
        <span class="n">label</span><span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Componente </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>

<span class="n">make_ellipses</span><span class="p">(</span><span class="n">modelo_gmm</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Distribuci√≥n de prob. de cada componente&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>


<span class="c1"># Distribuci√≥n de probabilidad del modelo completo</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]),</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">modelo_gmm</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()],</span> <span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.6</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">tab10</span><span class="p">(</span><span class="n">clasificacion</span><span class="p">))</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span> <span class="c1"># Las probabilidades est√°n en log</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
    <span class="n">levels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">))[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Distribuci√≥n de prob. del modelo completo&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* &amp; *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* &amp; *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* &amp; *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* &amp; *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
</pre></div>
</div>
<img alt="../../../../_images/03_clustering_70_4.png" src="../../../../_images/03_clustering_70_4.png" />
</div>
</div>
<p><strong>N√∫mero de clusters</strong></p>
<p>Dado que los modelos GMM son modelos probabil√≠sticos, se puede recurrir a m√©tricas como el Akaike information criterion (AIC) o Bayesian information criterion (BIC) para identificar c√≥mo de bien se ajustan los datos observados a modelo creado.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_components</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
<span class="n">valores_bic</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valores_aic</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">n_components</span><span class="p">:</span>
    <span class="n">modelo</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">covariance_type</span><span class="o">=</span><span class="s2">&quot;full&quot;</span><span class="p">)</span>
    <span class="n">modelo</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">valores_bic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">modelo</span><span class="o">.</span><span class="n">bic</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    <span class="n">valores_aic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">modelo</span><span class="o">.</span><span class="n">aic</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">valores_bic</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;BIC&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">valores_aic</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;AIC&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Valores BIC y AIC&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;N√∫mero componentes&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_72_0.png" src="../../../../_images/03_clustering_72_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;N√∫mero √≥ptimo acorde al BIC: </span><span class="si">{</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">valores_bic</span><span class="p">)]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;N√∫mero √≥ptimo acorde al AIC: </span><span class="si">{</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">valores_aic</span><span class="p">)]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>N√∫mero √≥ptimo acorde al BIC: 4
N√∫mero √≥ptimo acorde al AIC: 4
</pre></div>
</div>
</div>
</div>
<p>Ambas m√©tricas identifican el 4 como n√∫mero √≥ptimo de clusters (componentes).</p>
</div>
</div>
<div class="section" id="limitaciones-del-clustering">
<h2>Limitaciones del clustering<a class="headerlink" href="#limitaciones-del-clustering" title="Permalink to this headline">¬∂</a></h2>
<p>El clustering puede ser una herramienta muy √∫til para encontrar agrupaciones en los datos, sobre todo a medida que el volumen de los mismos aumenta. Sin embargo, es importante recordar sus limitaciones o problemas que pueden surgir al aplicarlo. Algunas de ellas son:</p>
<ul class="simple">
<li><p>Peque√±as decisiones pueden tener grandes consecuencias:a la hora de utilizar los m√©todos de clustering se tienen que tomar decisiones que influyen en gran medida en los resultados obtenidos. No existe una √∫nica respuesta correcta, por lo que en la pr√°ctica se prueban diferentes opciones.</p>
<ul>
<li><p>Escalado y centrado de las variables</p></li>
<li><p>Qu√© medida de distancia/similitud emplear</p></li>
<li><p>N√∫mero de clusters</p></li>
<li><p>Tipo de linkage empleado en hierarchical clustering</p></li>
<li><p>A que altura establecer el corte de un dendrograma</p></li>
</ul>
</li>
<li><p>Validaci√≥n de los clusters obtenidos: no es f√°cil comprobar la validez de los resultados ya que en la mayor√≠a de escenarios se desconoce la verdadera agrupaci√≥n.</p></li>
<li><p>Falta de robustez: los m√©todos de K-means-clustering e hierarchical clustering asignan obligatoriamente cada observaci√≥n a un grupo. Si existe en la muestra alg√∫n outlier, a pesar de que realmente no pertenezca a ning√∫n grupo, el algoritmo lo asignar√° a uno de ellos provocando una distorsi√≥n significativa del cluster en cuesti√≥n. Algunas alternativas son k-medoids y DBSCAN.</p></li>
<li><p>La naturaleza del algoritmo de hierarchical clustering conlleva que, si se realiza una mala divisi√≥n en los pasos iniciales, no se pueda corregir en los pasos siguientes.</p></li>
</ul>
</div>
<div class="section" id="referencias">
<h2>Referencias<a class="headerlink" href="#referencias" title="Permalink to this headline">¬∂</a></h2>
<ol class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/unsupervised_learning.html">Unsupervised learning</a></p></li>
<li><p><a class="reference external" href="https://www.cienciadedatos.net/documentos/py20-clustering-con-python.html">Clustering con Python (Joaqu√≠n Amat Rodrigo)</a></p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./mat281/lectures/ml/analisis_no_supervisado"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../introduccion_ml/no_supervisados.html" title="previous page">Aprendizaje no supervisado</a>
    <a class='right-next' id="next-link" href="03_reduccion_dimensionalidad.html" title="next page">Reducci√≥n de dimensionalidad</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Francisco Alfaro Medina<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-177357392-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>