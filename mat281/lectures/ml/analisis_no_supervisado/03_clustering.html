
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Clustering &#8212; Aplicaciones de la Matematica en la Ingenieria</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="shortcut icon" href="../../../../_static/logo_python.jpeg"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Reducción de dimensionalidad" href="03_reduccion_dimensionalidad.html" />
    <link rel="prev" title="Aprendizaje no supervisado" href="../introduccion_ml/no_supervisados.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
      <img src="../../../../_static/logo_python.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Aplicaciones de la Matematica en la Ingenieria</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../index.html">
   Home
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Herramientas Básicas
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../basic_tools/lecture_000_intro.html">
   Introducción
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basic_tools/lecture_000_configuraciones.html">
     Configuraciones
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_011_os.html">
   Linux
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_015_git.html">
   Git
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_013_ide.html">
   IDE’s
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_016_venv.html">
   Virtual Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_012_python.html">
   Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../basic_tools/lecture_014_jupyter.html">
   Jupyter
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Computación cientifica
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/scientific_computing/numpy.html">
   Numpy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/scientific_computing/scipy.html">
   SciPy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/scientific_computing/sympy.html">
   Sympy
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Manipulación de datos
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/data_manipulation/base_datos.html">
   Base de datos
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data_manipulation/data_manipulation/pandas/pandas.html">
   Pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/data_manipulation/modulos_pandas/groupby.html">
     Groupby
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/data_manipulation/modulos_pandas/merge_concat.html">
     Merge &amp; Concat
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/data_manipulation/modulos_pandas/pivot.html">
     Pivot
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/data_manipulation/sqlalchemy/sqlalchemy.html">
   SQLAlchemy
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Visualización
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/introduction.html">
   Introducción
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/imperativa.html">
   Visualización Imperativa
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/matplotlib.html">
     Matplotlib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/declarativa.html">
   Visualización Declarativa
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../data_manipulation/visualization/visualizacion/seaborn.html">
     Seaborn
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Análisis exploratorio de datos
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/eda/intro.html">
   Introducción
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../data_manipulation/eda/eda.html">
   Caso Aplicado
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduccion_ml/introduccion.html">
   Introducción
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../analisis_supervisado_regresion/intro.html">
   Aprendizaje supervisado - Regresión
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis_supervisado_regresion/02_regresion_lineal.html">
     Modelos de regressión lineal
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis_supervisado_regresion/02_modelos_regresion.html">
     Modelos de regressión multiple
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../analisis_supervisado_clasificacion/intro.html">
   Aprendizaje supervisado - Clasificación
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis_supervisado_clasificacion/02_clasificacion.html">
     Modelo de regresión logística
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../introduccion_ml/no_supervisados.html">
   Aprendizaje no supervisado
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_reduccion_dimensionalidad.html">
     Reducción de dimensionalidad
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../overfitting/04_overfitting_underfitting.html">
   Overfitting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../overfitting/04_reducir_overfitting.html">
     Reducir el overfitting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../time_series/05_series_temporales.html">
   Series Temporales
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../../_sources/mat281/lectures/ml/analisis_no_supervisado/03_clustering.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://gitlab.com/FAAM/mat281_2021"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-means">
   K-means
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#teoria">
     Teoría
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algoritmo">
     Algoritmo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ventajas-y-desventajas">
     Ventajas y desventajas
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aplicacion">
     Aplicación
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#regla-del-codo">
       Regla del codo
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hierarchical-clustering">
   Hierarchical clustering
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Teoría
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Algoritmo
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#aglomerativo">
       Aglomerativo
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#divisivo">
       Divisivo
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dendograma">
     Dendograma
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Aplicación
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#density-based-clustering-dbscan">
   Density based clustering (DBSCAN)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Teoría
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     Algoritmo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hiperparametros">
     Hiperparámetros
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       Ventajas y desventajas
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     Aplicación
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-mixture-models-gmms">
   Gaussian mixture models (GMMs)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     Teoría
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     Algoritmo
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     Aplicación
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#limitaciones-del-clustering">
   Limitaciones del clustering
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#referencias">
   Referencias
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="clustering">
<h1>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h1>
<p>El <strong>Clustering</strong> es la tarea de agrupar objetos por similitud, en grupos o conjuntos de manera que los miembros del mismo grupo tengan características similares. Es la tarea principal de la minería de datos exploratoria y es una técnica común en el análisis de datos estadísticos.</p>
<a class="reference internal image-reference" href="../../../../_images/clust.png"><img alt="../../../../_images/clust.png" class="align-center" src="../../../../_images/clust.png" style="width: 480px; height: 300px;" /></a>
<div class="section" id="k-means">
<h2>K-means<a class="headerlink" href="#k-means" title="Permalink to this headline">¶</a></h2>
<div class="section" id="teoria">
<h3>Teoría<a class="headerlink" href="#teoria" title="Permalink to this headline">¶</a></h3>
<p>El algoritmo <a class="reference external" href="https://es.wikipedia.org/wiki/K-means">K-means</a>  (MacQueen, 1967) agrupa las observaciones en un número predefinido de <span class="math notranslate nohighlight">\(k\)</span> clusters de forma que, la suma de las varianzas internas de los clusters, sea lo menor posible.</p>
<p>Existen varias implementaciones de este algoritmo, la más común de ellas se conoce como Lloyd’s. En la bibliografía es común encontrar los términos inertia, within-cluster sum-of-squares o varianza intra-cluster para referirse a la varianza interna de los clusters.</p>
<p>Considérense  <span class="math notranslate nohighlight">\(𝐶_1 ,...,  𝐶_k\)</span>  como los sets formados por los índices de las observaciones de cada uno de los clusters. Por ejemplo, el set  <span class="math notranslate nohighlight">\(𝐶_1\)</span>  contiene los índices de las observaciones agrupadas en el cluster 1. La nomenclatura empleada para indicar que la observación  <span class="math notranslate nohighlight">\(i\)</span> pertenece al cluster  <span class="math notranslate nohighlight">\(k\)</span>  es:  <span class="math notranslate nohighlight">\(i \in C_k\)</span> . Todos los sets satisfacen dos propiedades:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(C_1 \cup C_2 \cup ... \cup C_k = {1,...,n} \)</span> . Significa que toda observación pertenece a uno de los <span class="math notranslate nohighlight">\(k\)</span> clusters.</p></li>
<li><p><span class="math notranslate nohighlight">\(C_i \cap C_{j} = \emptyset \)</span>   para todo <span class="math notranslate nohighlight">\(i \neq j\)</span>   . Implica que los clusters no solapan, ninguna observación pertenece a más de un cluster a la vez.</p></li>
</ul>
<p>El algoritmo consiste en reducir al mínimo la suma de las distancias cuadradas desde la media dentro del agrupamiento. Matemáticamente:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
(P) \ \textrm{Minimizar } f(C_l,\mu_l) = \sum_{l=1}^k \sum_{x_n \in C_l} ||x_n - \mu_l ||^2 \textrm{, respecto a } C_l, \mu_l,
\end{align*}\]</div>
<p>donde <span class="math notranslate nohighlight">\(C_l\)</span> es el cluster l-ésimo y <span class="math notranslate nohighlight">\(\mu_l\)</span> es el centroide l-ésimo.</p>
<a class="reference internal image-reference" href="../../../../_images/kmean_01.png"><img alt="../../../../_images/kmean_01.png" class="align-center" src="../../../../_images/kmean_01.png" style="width: 480px; height: 300px;" /></a>
</div>
<div class="section" id="algoritmo">
<h3>Algoritmo<a class="headerlink" href="#algoritmo" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Especificar el número <span class="math notranslate nohighlight">\(k\)</span> de clusters que se quieren crear.</p></li>
<li><p>Seleccionar de forma aleatoria <span class="math notranslate nohighlight">\(k\)</span> observaciones del set de datos como centroides iniciales.</p></li>
<li><p>Asignar cada una de las observaciones al centroide más cercano.</p></li>
<li><p>Para cada uno de los <span class="math notranslate nohighlight">\(k\)</span> clusters generados en el paso 3, recalcular su centroide.</p></li>
</ol>
<p>Repetir los pasos 3 y 4 hasta que las asignaciones no cambien o se alcance el número máximo de iteraciones establecido.</p>
<p>El problema anterior es NP-hard (imposible de resolver en tiempo polinomial, del tipo más difícil de los probleams NP).</p>
</div>
<div class="section" id="ventajas-y-desventajas">
<h3>Ventajas y desventajas<a class="headerlink" href="#ventajas-y-desventajas" title="Permalink to this headline">¶</a></h3>
<p>K-means es uno de los métodos de clustering más utilizados. Destaca por la sencillez y velocidad de su algoritmo, sin embargo, presenta una serie de limitaciones que se deben tener en cuenta.</p>
<ul class="simple">
<li><p>Requiere que se indique de antemano el número de clusters que se van a crear. Esto puede ser complicado si no se dispone de información adicional sobre los datos con los que se trabaja. Se han desarrollado varias estrategias para ayudar a identificar potenciales valores óptimos de <span class="math notranslate nohighlight">\(k\)</span> (elbow, shilouette), pero todas ellas son orientativas.</p></li>
<li><p>Dificultad para detectar clusters alargados o con formas irregulares.</p></li>
<li><p>Las agrupaciones resultantes pueden variar dependiendo de la asignación aleatoria inicial de los centroides. Para minimizar este problema, se recomienda repetir el proceso de clustering entre 25-50 veces y seleccionar como resultado definitivo el que tenga menor suma total de varianza interna. Aun así, solo se puede garantizar la reproducibilidad de los resultados si se emplean semillas.</p></li>
<li><p>Presenta problemas de robustez frente a outliers.</p></li>
</ul>
</div>
<div class="section" id="aplicacion">
<h3>Aplicación<a class="headerlink" href="#aplicacion" title="Permalink to this headline">¶</a></h3>
<p>Veamos un ejemplo de análisis no supervisado ocupando el algoritmo <strong>k-means</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># librerias</span>
 
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span> 

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>  <span class="c1"># Ver más columnas de los dataframes</span>

<span class="c1"># Ver gráficos de matplotlib en jupyter notebook/lab</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">init_blobs</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
                      <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.60</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="c1"># generar datos</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">init_blobs</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">43</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">])</span>



<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-6.953617</td>
      <td>-4.989933</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-2.681117</td>
      <td>7.583914</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.510161</td>
      <td>4.933676</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-9.748491</td>
      <td>5.479457</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-7.438017</td>
      <td>-4.597754</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Debido a que trabajamos con el concepto de distancia, muchas veces las columnas del dataframe pueden estar en distintas escalas, lo cual puede complicar a los algoritmos ocupados (al menos con <strong>sklearn</strong>).</p>
<p>En estos casos, se suele <strong>normalizar</strong> los atributos, es decir, dejar los valores en una escala acotada y/o con estimadores fijos. Por ejemplo, en *<strong>sklearn</strong> podemos encontrar las siguientes formas de normalizar:</p>
<ul class="simple">
<li><p><strong>StandardScaler</strong>: se normaliza  restando la media y escalando por su desviación estanda.
$<span class="math notranslate nohighlight">\(x_{prep} = \dfrac{x-u}{s}\)</span>$</p></li>
</ul>
<p>La ventaja es que la media del nuevo conjunto de datos cumple con la propiedad que su media <span class="math notranslate nohighlight">\(\mu\)</span> es igual a cero y su desviación estandar <span class="math notranslate nohighlight">\(s\)</span> es igual a 1.</p>
<ul class="simple">
<li><p><strong>MinMaxScaler</strong>:  se normaliza ocupando los valores de los mínimos y máximo del conjunto de datos.
$<span class="math notranslate nohighlight">\(x_{prep} = \dfrac{x-x_{min}}{x_{min}-x_{max}}\)</span>$</p></li>
</ul>
<p>Esta forma de normalizar resulta útil cuando la desviación estandar <span class="math notranslate nohighlight">\(s\)</span> es muy pequeña (cercana) a cero, por lo que lo convierte en un estimador más roubusto que el <strong>StandardScaler</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">])</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.579033</td>
      <td>-1.831435</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.408821</td>
      <td>1.194578</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.679560</td>
      <td>0.556774</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.225241</td>
      <td>0.688121</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.691032</td>
      <td>-1.737053</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># comprobar resultados del estimador</span>
<span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1.000000e+04</td>
      <td>1.000000e+04</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.060574e-16</td>
      <td>-2.285105e-15</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.000050e+00</td>
      <td>1.000050e+00</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-1.638247e+00</td>
      <td>-2.410317e+00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-8.015576e-01</td>
      <td>-4.418042e-01</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-2.089351e-01</td>
      <td>1.863259e-01</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>5.480066e-01</td>
      <td>8.159808e-01</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2.243358e+00</td>
      <td>1.639547e+00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Con esta parametrización procedemos a graficar nuestros resultados:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar </span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mf">11.7</span><span class="p">,</span><span class="mf">8.27</span><span class="p">)})</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_12_0.png" src="../../../../_images/03_clustering_12_0.png" />
</div>
</div>
<p>Ahora ajustamos el algoritmo <strong>KMeans</strong> de <strong>sklearn</strong>. Primero, comprendamos los hiperparámetros más importantes:</p>
<ul class="simple">
<li><p><strong>n_clusters</strong>: El número de clusters a crear, o sea <strong>K</strong>. Por defecto es 8</p></li>
<li><p><strong>init</strong>: Método de inicialización. Un problema que tiene el algoritmo K-Medias es que la solucción alcanzada varia según la inicialización de los centroides. <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> empieza usando el método <code class="docutils literal notranslate"><span class="pre">kmeans++</span></code> que es una versión más moderna y que proporciona mejores resultados que la inicialización aleatoria (random)</p></li>
<li><p><strong>n_init</strong>: El número de inicializaciones a probar. Básicamente <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> aplica el algoritmo <code class="docutils literal notranslate"><span class="pre">n_init</span></code> veces y elige los clusters que minimizan la inercia.</p></li>
<li><p><strong>max_iter</strong>: Máximo número de iteraciones para llegar al criterio de parada.</p></li>
<li><p><strong>random_state</strong>: semilla para garantizar la reproducibilidad de los resultados.</p></li>
<li><p><strong>tol</strong>: Tolerancia para declarar criterio de parada (cuanto más grande, antes parará el algoritmo).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ajustar modelo: k-means</span>

<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span><span class="n">n_init</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="n">centroids</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span> <span class="c1"># centros </span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span> <span class="c1"># clusters</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># etiquetar los datos con los clusters encontrados</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clusters</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>
<span class="n">centroids_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">centroids</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="n">centroids_df</span><span class="p">[</span><span class="s2">&quot;cluster&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar los datos etiquetados con k-means</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mf">8.5</span><span class="p">))</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
                     <span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span>
                     <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span>
                     <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;cluster&quot;</span><span class="p">,</span>
                     <span class="n">legend</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span>
                     <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;Set2&quot;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span>
                     <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">centroids_df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/runner/.cache/pypoetry/virtualenvs/mat281-2021-V7B8LTfe-py3.8/lib/python3.8/site-packages/seaborn/relational.py:651: UserWarning: You passed a edgecolor/edgecolors (&#39;w&#39;) for an unfilled marker (&#39;x&#39;).  Matplotlib is ignoring the edgecolor in favor of the facecolor.  This behavior may change in the future.
  points = ax.scatter(*args, **kws)
</pre></div>
</div>
<img alt="../../../../_images/03_clustering_16_1.png" src="../../../../_images/03_clustering_16_1.png" />
</div>
</div>
<p>Ahora la pregunta que surge de manera natural es … ¿ cómo escoger el mejor número de clusters?.</p>
<p>No existe un criterio objetivo ni ampliamente válido para la  elección de un número óptimo de clusters. Aunque no exista un criterio objetivo para la selección del número de clusters, si que se han implementado diferentes métodos que nos ayudan a elegir un número apropiado de clusters para agrupar los datos; como son,</p>
<ul class="simple">
<li><p>método del codo (elbow method)</p></li>
<li><p>criterio de Calinsky</p></li>
<li><p>Affinity Propagation (AP)</p></li>
<li><p>Gap (también con su versión estadística)</p></li>
<li><p>Dendrogramas</p></li>
<li><p>etc.</p></li>
</ul>
<div class="section" id="regla-del-codo">
<h4>Regla del codo<a class="headerlink" href="#regla-del-codo" title="Permalink to this headline">¶</a></h4>
<p>Este método utiliza los valores de la función de perdida, <span class="math notranslate nohighlight">\(f(C_l,\mu_l)\)</span>, obtenidos tras aplicar el <span class="math notranslate nohighlight">\(K\)</span>-means a diferente número de Clusters (desde 1 a <span class="math notranslate nohighlight">\(N\)</span> clusters).</p>
<p>Una vez obtenidos los valores de la función de pérdida  tras aplicar el K-means de 1 a <span class="math notranslate nohighlight">\(N\)</span> clusters, representamos en una gráfica lineal la función de pérdida  respecto del número de clusters.</p>
<p>En esta gráfica se debería de apreciar un cambio brusco en la evolución de la función de pérdida, teniendo la línea representada una forma similar a la de un brazo y su codo.</p>
<p>El punto en el que se observa ese cambio brusco en la función de pérdida nos dirá el número óptimo de clusters a seleccionar para ese data set; o dicho de otra manera: el punto que representaría al codo del brazo será el número óptimo de clusters para ese data set
.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># implementación de la regla del codo</span>
<span class="n">Nc</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="p">[</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">Nc</span><span class="p">]</span>
<span class="n">score</span> <span class="o">=</span> <span class="p">[</span><span class="n">kmeans</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">inertia_</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">kmeans</span><span class="p">))]</span>


<span class="n">df_Elbow</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Number of Clusters&#39;</span><span class="p">:</span><span class="n">Nc</span><span class="p">,</span>
                        <span class="s1">&#39;Score&#39;</span><span class="p">:</span><span class="n">score</span><span class="p">})</span>

<span class="n">df_Elbow</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Number of Clusters</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>49337.951600</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>20004.858535</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>12733.014667</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>6760.679396</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>3139.657771</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar los datos etiquetados con k-means</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mf">8.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Elbow Curve&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Number of Clusters&quot;</span><span class="p">,</span>
             <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Score&quot;</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">df_Elbow</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Number of Clusters&quot;</span><span class="p">,</span>
             <span class="n">y</span><span class="o">=</span><span class="s2">&quot;Score&quot;</span><span class="p">,</span>
             <span class="n">data</span><span class="o">=</span><span class="n">df_Elbow</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_19_0.png" src="../../../../_images/03_clustering_19_0.png" />
</div>
</div>
<p>A partir de 4 clusters la reducción en la suma total de cuadrados internos parece estabilizarse, indicando que <span class="math notranslate nohighlight">\(k\)</span> = 4 es una buena opción.</p>
</div>
</div>
</div>
<div class="section" id="hierarchical-clustering">
<h2>Hierarchical clustering<a class="headerlink" href="#hierarchical-clustering" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Teoría<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Hierarchical clustering es una alternativa a los métodos de partitioning clustering que no requiere que se pre-especifique el número de clusters. Los métodos que engloba el hierarchical clustering se subdividen en dos tipos dependiendo de la estrategia seguida para crear los grupos:</p>
<ul class="simple">
<li><p><strong>Aglomerativo</strong> (agglomerative clustering o bottom-up): el agrupamiento se inicia con todas las observaciones separadas, cada una formando un cluster individual. Los clusters se van combinado a medida que la estructura crece hasta converger en uno solo.</p></li>
<li><p><strong>Divisivo</strong> (divisive clustering o top-down): es la estrategia opuesta al aglomerativo. Se inicia con todas las observaciones contenidas en un mismo cluster y se suceden divisiones hasta que cada observación forma un cluster* individual.</p></li>
</ul>
<p>En ambos casos, los resultados pueden representarse de forma muy intuitiva en una estructura de árbol llamada dendrograma.</p>
</div>
<div class="section" id="id2">
<h3>Algoritmo<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="section" id="aglomerativo">
<h4>Aglomerativo<a class="headerlink" href="#aglomerativo" title="Permalink to this headline">¶</a></h4>
<p>El algoritmo seguido para por el clustering aglomerativo es:</p>
<ol class="simple">
<li><p>Considerar cada una de las n observaciones como un cluster individual, formando así la base del dendrograma (hojas).</p></li>
<li><p>Proceso iterativo hasta que todas las observaciones pertenecen a un único cluster:</p>
<ul class="simple">
<li><p>Calcular la distancia entre cada posible par de los n clusters. El investigador debe determinar el tipo de medida empleada para cuantificar la similitud entre observaciones o grupos (distancia y linkage).</p></li>
<li><p>Los dos clusters más similares se fusionan, de forma que quedan n-1 clusters.</p></li>
</ul>
</li>
<li><p>Cortar la estructura de árbol generada (dendrograma) a una determinada altura para crear los clusters finales.</p></li>
</ol>
<p>Para que el proceso de agrupamiento pueda llevarse a cabo tal como indica el algoritmo anterior, es necesario definir cómo se cuantifica la similitud entre dos clusters. Es decir, se tiene que extender el concepto de distancia entre pares de observaciones para que sea aplicable a pares de grupos, cada uno formado por varias observaciones. A este proceso se le conoce como linkage. A continuación, se describen los 5 tipos de linkage más empleados y sus definiciones.</p>
<ul class="simple">
<li><p><strong>Complete or Maximum</strong>: se calcula la distancia entre todos los posibles pares formados por una observación del cluster A y una del cluster B. La mayor de todas ellas se selecciona como la distancia entre los dos clusters. Se trata de la medida más conservadora (maximal intercluster dissimilarity).</p></li>
<li><p><strong>Single or Minimum</strong>: se calcula la distancia entre todos los posibles pares formados por una observación del cluster A y una del cluster B. La menor de todas ellas se selecciona como la distancia entre los dos clusters. Se trata de la medida menos conservadora (minimal intercluster dissimilarity).</p></li>
<li><p><strong>Average</strong>: Se calcula la distancia entre todos los posibles pares formados por una observación del cluster A y una del cluster B. El valor promedio de todas ellas se selecciona como la distancia entre los dos clusters (mean intercluster dissimilarity).</p></li>
<li><p><strong>Centroid</strong>: Se calcula el centroide de cada uno de los clusters y se selecciona la distancia entre ellos como la distancia entre los dos clusters.</p></li>
<li><p><strong>Ward</strong>: Se trata de un método general. La selección del par de clusters que se combinan en cada paso del agglomerative hierarchical clustering se basa en el valor óptimo de una función objetivo, pudiendo ser esta última cualquier función definida por el analista. El método Ward’s minimum variance es un caso particular en el que el objetivo es minimizar la suma total de varianza intra-cluster. En cada paso, se identifican aquellos 2 clusters cuya fusión conlleva menor incremento de la varianza total intra-cluster. Esta es la misma métrica que se minimiza en K-means.</p></li>
</ul>
<p>Los métodos de complete, average y Ward’s minimum variance suelen ser los preferidos por los analistas debido a que generan dendrogramas más compensados. Sin embargo, no se puede determinar que uno sea mejor que otro, ya que depende del caso de estudio en cuestión. Por ejemplo, en genómica, se emplea con frecuencia el método de centroides. Junto con los resultados de un proceso de hierarchical clustering siempre hay que indicar qué distancia se ha empleado, así como el tipo de linkage, ya que, dependiendo de estos, los resultados pueden variar en gran medida.</p>
</div>
<div class="section" id="divisivo">
<h4>Divisivo<a class="headerlink" href="#divisivo" title="Permalink to this headline">¶</a></h4>
<p>El algoritmo más conocido de divisive hierarchical clustering es DIANA (DIvisive ANAlysis Clustering). Este algoritmo se inicia con un único cluster que contiene todas las observaciones. A continuación, se van sucediendo divisiones hasta que cada observación forma un cluster independiente. En cada iteración, se selecciona el cluster con mayor diámetro, entendiendo por diámetro de un cluster la mayor de las diferencias entre dos de sus observaciones. Una vez seleccionado el cluster, se identifica la observación más dispar, que es aquella con mayor distancia promedio respecto al resto de observaciones que forman el cluster. Esta observación inicia el nuevo cluster. Se reasignan las observaciones en función de si están más próximas al nuevo cluster o al resto de la partición, dividiendo así el cluster seleccionado en dos nuevos clusters.</p>
<ol class="simple">
<li><p>Todas las <span class="math notranslate nohighlight">\(n\)</span> observaciones forman un único cluster.</p></li>
<li><p>Repetir hasta que haya <span class="math notranslate nohighlight">\(n\)</span> clusters:</p>
<ul class="simple">
<li><p>Calcular para cada cluster la mayor de las distancias entre pares de observaciones (diámetro del cluster).</p></li>
<li><p>Seleccionar el cluster con mayor diámetro.</p></li>
<li><p>Calcular la distancia media de cada observación respecto a las demás.</p></li>
<li><p>La observación más distante inicia un nuevo cluster.</p></li>
<li><p>Se reasignan las observaciones restantes al nuevo cluster o al viejo dependiendo de cuál está más próximo.</p></li>
</ul>
</li>
</ol>
<p>A diferencia del clustering aglomerativo, en el que hay que elegir un tipo de distancia y un método de linkage, en el clustering divisivo solo hay que elegir la distancia, no hay linkage.</p>
</div>
</div>
<div class="section" id="dendograma">
<h3>Dendograma<a class="headerlink" href="#dendograma" title="Permalink to this headline">¶</a></h3>
<p>Los resultados del hierarchical clustering pueden representarse como un árbol en el que las ramas representan la jerarquía con la que se van sucediendo las uniones de clusters.</p>
<p>Supóngase que se dispone de 45 observaciones en un espacio de dos dimensiones, a los que se les aplica hierarchical clustering para intentar identificar grupos. El siguiente dendrograma representa los resultados obtenidos.</p>
<img alt="../../../../_images/hc_01.png" class="align-center" src="../../../../_images/hc_01.png" />
<p>En la base del dendrograma, cada observación forma una terminación individual conocida como hoja o leaf del árbol. A medida que se asciende por la estructura, pares de hojas se fusionan formando las primeras ramas. Estas uniones se corresponden con los pares de observaciones más similares. También ocurre que las ramas se fusionan con otras ramas o con hojas. Cuanto más temprana (más próxima a la base del dendrograma) ocurre una fusión, mayor es la similitud.</p>
<p>Para cualquier par de observaciones, se puede identificar el punto del árbol en el que las ramas que contienen dichas observaciones se fusionan. La altura a la que esto ocurre (eje vertical) indica cómo de similares/diferentes son las dos observaciones. Los dendrogramas, por lo tanto, se deben interpretar únicamente en base al eje vertical y no por las posiciones que ocupan las observaciones en el eje horizontal, esto último es simplemente por estética y puede variar de un programa a otro.</p>
<p>Por ejemplo, la observación 8 es la más similar a la 10 ya que es la primera fusión que recibe la observación 10 (y viceversa). Podría resultar tentador decir que la observación 14, situada inmediatamente a la derecha de la 10, es la siguiente más similar, sin embargo, las observaciones 28 y 44 son más similares a la 10 a pesar de que se encuentran más alejadas en el eje horizontal. Del mismo modo, no es correcto decir que la observación 14 es más similar a la observación 10 de lo que lo es la 36 por el hecho de que está más próxima en el eje horizontal. Prestando atención a la altura en que las respectivas ramas se unen, la única conclusión válida es que la similitud entre los pares 10-14 y 10-36 es la misma.</p>
<p><strong>Cortar el dendograma para generar los clusters</strong></p>
<p>Además de representar en un dendrograma la similitud entre observaciones, se tiene que identificar el número de clusters creados y qué observaciones forman parte de cada uno. Si se realiza un corte horizontal a una determinada altura del dendrograma, el número de ramas que sobrepasan (en sentido ascendente) dicho corte se corresponde con el número de clusters. La siguiente imagen muestra dos veces el mismo dendrograma. Si se realiza el corte a la altura de 5, se obtienen dos clusters, mientras que si se hace a la de 3.5 se obtienen 4. La altura de corte tiene por lo tanto la misma función que el valor K en K-means-clustering: controla el número de clusters obtenidos.</p>
<a class="reference internal image-reference" href="../../../../_images/hc_02.png"><img alt="../../../../_images/hc_02.png" class="align-center" src="../../../../_images/hc_02.png" style="width: 600px; height: 600px;" /></a>
<a class="reference internal image-reference" href="../../../../_images/hc_03.png"><img alt="../../../../_images/hc_03.png" class="align-center" src="../../../../_images/hc_03.png" style="width: 600px; height: 600px;" /></a>
<p>Dos propiedades adicionales se derivan de la forma en que se generan los clusters en el método de hierarchical clustering:</p>
<ul class="simple">
<li><p>Dada la longitud variable de las ramas, siempre existe un intervalo de altura para el que cualquier corte da lugar al mismo número de clusters. En el ejemplo anterior, todos los cortes entre las alturas 5 y 6 tienen como resultado los mismos 2 clusters.</p></li>
<li><p>Con un solo dendrograma se dispone de la flexibilidad para generar cualquier número de clusters desde 1 a n. La selección del número óptimo puede valorarse de forma visual, tratando de identificar las ramas principales en base a la altura a la que ocurren las uniones. En el ejemplo expuesto es razonable elegir entre 2 o 4 clusters.</p></li>
</ul>
</div>
<div class="section" id="id3">
<h3>Aplicación<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tratamiento de datos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="c1"># Gráficos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">style</span>
<span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

<span class="c1"># Preprocesado y modelado</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">dendrogram</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="c1"># Configuración warnings</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generar datos</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span>
        <span class="n">n_samples</span>    <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> 
        <span class="n">n_features</span>   <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> 
        <span class="n">centers</span>      <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> 
        <span class="n">cluster_std</span>  <span class="o">=</span> <span class="mf">0.60</span><span class="p">,</span> 
        <span class="n">shuffle</span>      <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
        <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span>
       <span class="p">)</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;x&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
    <span class="s1">&#39;y&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="p">})</span>


<span class="c1"># Escalado de datos</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">])</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.348818</td>
      <td>-0.908114</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.638621</td>
      <td>-0.534950</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.653079</td>
      <td>0.027910</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.573023</td>
      <td>1.276049</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.970706</td>
      <td>-1.418431</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar </span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mf">11.7</span><span class="p">,</span><span class="mf">8.27</span><span class="p">)})</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_30_0.png" src="../../../../_images/03_clustering_30_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Modelos</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># primer modelo</span>
<span class="n">modelo_hclust_complete</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span>
                            <span class="n">affinity</span> <span class="o">=</span> <span class="s1">&#39;euclidean&#39;</span><span class="p">,</span>
                            <span class="n">linkage</span>  <span class="o">=</span> <span class="s1">&#39;complete&#39;</span><span class="p">,</span>
                            <span class="n">distance_threshold</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                            <span class="n">n_clusters</span>         <span class="o">=</span> <span class="kc">None</span>
                        <span class="p">)</span>
<span class="n">modelo_hclust_complete</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AgglomerativeClustering(distance_threshold=0, linkage=&#39;complete&#39;,
                        n_clusters=None)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># segundo modelo</span>
<span class="n">modelo_hclust_average</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span>
                            <span class="n">affinity</span> <span class="o">=</span> <span class="s1">&#39;euclidean&#39;</span><span class="p">,</span>
                            <span class="n">linkage</span>  <span class="o">=</span> <span class="s1">&#39;average&#39;</span><span class="p">,</span>
                            <span class="n">distance_threshold</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                            <span class="n">n_clusters</span>         <span class="o">=</span> <span class="kc">None</span>
                        <span class="p">)</span>
<span class="n">modelo_hclust_average</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AgglomerativeClustering(distance_threshold=0, linkage=&#39;average&#39;,
                        n_clusters=None)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tercer modelo</span>
<span class="n">modelo_hclust_ward</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span>
                            <span class="n">affinity</span> <span class="o">=</span> <span class="s1">&#39;euclidean&#39;</span><span class="p">,</span>
                            <span class="n">linkage</span>  <span class="o">=</span> <span class="s1">&#39;ward&#39;</span><span class="p">,</span>
                            <span class="n">distance_threshold</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                            <span class="n">n_clusters</span>         <span class="o">=</span> <span class="kc">None</span>
                     <span class="p">)</span>
<span class="n">modelo_hclust_ward</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AgglomerativeClustering(distance_threshold=0, n_clusters=None)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_dendrogram</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Esta función extrae la información de un modelo AgglomerativeClustering</span>
<span class="sd">    y representa su dendograma con la función dendogram de scipy.cluster.hierarchy</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">children_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">merge</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">children_</span><span class="p">):</span>
        <span class="n">current_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">child_idx</span> <span class="ow">in</span> <span class="n">merge</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">child_idx</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
                <span class="n">current_count</span> <span class="o">+=</span> <span class="mi">1</span>  <span class="c1"># leaf node</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">current_count</span> <span class="o">+=</span> <span class="n">counts</span><span class="p">[</span><span class="n">child_idx</span> <span class="o">-</span> <span class="n">n_samples</span><span class="p">]</span>
        <span class="n">counts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_count</span>

    <span class="n">linkage_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">children_</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">distances_</span><span class="p">,</span>
                                      <span class="n">counts</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

    <span class="c1"># Plot</span>
    <span class="n">dendrogram</span><span class="p">(</span><span class="n">linkage_matrix</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dendrogramas</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> 
<span class="n">plot_dendrogram</span><span class="p">(</span><span class="n">modelo_hclust_average</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distancia euclídea, Linkage average&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_36_0.png" src="../../../../_images/03_clustering_36_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dendrogramas</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> 
<span class="n">plot_dendrogram</span><span class="p">(</span><span class="n">modelo_hclust_complete</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distancia euclídea, Linkage complete&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_37_0.png" src="../../../../_images/03_clustering_37_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dendrogramas</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> 
<span class="n">plot_dendrogram</span><span class="p">(</span><span class="n">modelo_hclust_ward</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distancia euclídea, Linkage ward&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_38_0.png" src="../../../../_images/03_clustering_38_0.png" />
</div>
</div>
<p>En este caso, los tres tipos de linkage identifican claramente 4 clusters, si bien esto no significa que en los 3 dendrogramas los clusters estén formados por exactamente las mismas observaciones.</p>
<p><strong>Número de clusters</strong></p>
<p>Una forma de identificar el número de clusters, es inspeccionar visualmente el dendograma y decidir a qué altura se corta para generar los clusters. Por ejemplo, para los resultados generados mediante distancia euclídea y linkage ward, parece sensato cortar el dendograma a una altura de entre 5 y 10, de forma que se creen 4 clusters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> 
<span class="n">altura_corte</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">plot_dendrogram</span><span class="p">(</span><span class="n">modelo_hclust_ward</span><span class="p">,</span> <span class="n">color_threshold</span><span class="o">=</span><span class="n">altura_corte</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distancia euclídea, Linkage ward&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">altura_corte</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;altura corte&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_41_0.png" src="../../../../_images/03_clustering_41_0.png" />
</div>
</div>
<p>Una vez identificado el número óptimo de clusters, se reentrena el modelo indicando este valor.</p>
</div>
</div>
<div class="section" id="density-based-clustering-dbscan">
<h2>Density based clustering (DBSCAN)<a class="headerlink" href="#density-based-clustering-dbscan" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id4">
<h3>Teoría<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>Density-based spatial clustering of applications with noise (DBSCAN) fue presentado en 1996 por Ester et al. como una forma de identificar clusters siguiendo el modo intuitivo en el que lo hace el cerebro humano, identificando regiones con alta densidad de observaciones separadas por regiones de baja densidad.</p>
<a class="reference internal image-reference" href="../../../../_images/dbs_01.png"><img alt="../../../../_images/dbs_01.png" class="align-center" src="../../../../_images/dbs_01.png" style="width: 480px; height: 300px;" /></a>
<p>El cerebro humano identifica fácilmente 5 agrupaciones y algunas observaciones aisladas (ruido). Véanse ahora los clusters que se obtienen si se aplica, por ejemplo, K-means clustering.</p>
<a class="reference internal image-reference" href="../../../../_images/dbs_02.png"><img alt="../../../../_images/dbs_02.png" class="align-center" src="../../../../_images/dbs_02.png" style="width: 480px; height: 300px;" /></a>
<p>Los clusters generados distan mucho de representar las verdaderas agrupaciones. Esto es así porque los métodos de partitioning clustering como k-means, hierarchical, k-medoids, … son buenos encontrando agrupaciones con forma esférica o convexa que no contengan un exceso de outliers o ruido, pero fallan al tratar de identificar formas arbitrarias. De ahí que el único cluster que se corresponde con un grupo real sea el amarillo.</p>
<p>DBSCAN evita este problema siguiendo la idea de que, para que una observación forme parte de un cluster, tiene que haber un mínimo de observaciones vecinas dentro de un radio de proximidad y de que los clusters están separados por regiones vacías o con pocas observaciones.</p>
<p>El algoritmo DBSCAN necesita dos parámetros:</p>
<ul class="simple">
<li><p>Epsilon  (<span class="math notranslate nohighlight">\(\epsilon\)</span>) : radio que define la región vecina a una observación, también llamada  𝜖 -neighborhood.</p></li>
<li><p>Minimum points (<span class="math notranslate nohighlight">\(min_samples\)</span>): número mínimo de observaciones dentro de la región epsilon.</p></li>
</ul>
<p>Empleando estos dos parámetros, cada observación del set de datos se puede clasificar en una de las siguientes tres categorías:</p>
<ul class="simple">
<li><p><strong>Core point</strong>: observación que tiene en su  𝜖 -neighborhood un número de observaciones vecinas igual o mayor a min_samples.</p></li>
<li><p><strong>Border point</strong>: observación no satisface el mínimo de observaciones vecinas para ser core point pero que pertenece al  <span class="math notranslate nohighlight">\(\epsilon\)</span>-neighborhood de otra observación que sí es core point.</p></li>
<li><p><strong>Noise-outlier</strong>: observación que no es core point ni border point.</p></li>
</ul>
<p>Por último, empleando las tres categorías anteriores se pueden definir tres niveles de conectividad entre observaciones:</p>
<ul class="simple">
<li><p>Directamente alcanzable (direct density reachable): una observación  <span class="math notranslate nohighlight">\(A\)</span>  es directamente alcanzable desde otra observación  <span class="math notranslate nohighlight">\(B\)</span>  si  <span class="math notranslate nohighlight">\(A\)</span>  forma parte del  <span class="math notranslate nohighlight">\(\epsilon\)</span> -neighborhood de  <span class="math notranslate nohighlight">\(B\)</span>  y  <span class="math notranslate nohighlight">\(B\)</span>  es un core point. Por definición, las observaciones solo pueden ser directamente alcanzables desde un core point.</p></li>
<li><p>Alcanzable (density reachable): una observación  <span class="math notranslate nohighlight">\(A\)</span>  es alcanzable desde otra observación  <span class="math notranslate nohighlight">\(𝐵\)</span>  si existe una secuencia de core points que van desde  <span class="math notranslate nohighlight">\(B\)</span>  a  <span class="math notranslate nohighlight">\(A\)</span> .</p></li>
<li><p>Densamente conectadas (density conected): dos observaciones <span class="math notranslate nohighlight">\(A\)</span>  y  <span class="math notranslate nohighlight">\(B\)</span>  están densamente conectadas si existe una observación core point  <span class="math notranslate nohighlight">\(C\)</span>  tal que  <span class="math notranslate nohighlight">\(A\)</span>  y  <span class="math notranslate nohighlight">\(B\)</span>  son alcanzables desde  <span class="math notranslate nohighlight">\(C\)</span> .</p></li>
</ul>
<p>La siguiente imagen muestra las conexiones existentes entre un conjunto de observaciones si se emplea  <span class="math notranslate nohighlight">\(min_samples = 4\)</span> . La observación  <span class="math notranslate nohighlight">\(A\)</span>  y el resto de observaciones marcadas en rojo son core points, ya que todas ellas contienen al menos 4 observaciones vecinas (incluyéndose a ellas mismas) en su  <span class="math notranslate nohighlight">\(\epsilon\)</span>-neighborhood. Como todas son alcanzables entre ellas, forman un cluster. Las observaciones  <span class="math notranslate nohighlight">\(B\)</span>  y  <span class="math notranslate nohighlight">\(C\)</span>  no son core points pero son alcanzables desde  <span class="math notranslate nohighlight">\(A\)</span>  a través de otros core points, por lo tanto, pertenecen al mismo cluster que  <span class="math notranslate nohighlight">\(A\)</span> . La observación  <span class="math notranslate nohighlight">\(N\)</span>  no es ni un core point ni es directamente alcanzable, por lo que se considera como ruido.</p>
<a class="reference internal image-reference" href="../../../../_images/dbs_03.png"><img alt="../../../../_images/dbs_03.png" class="align-center" src="../../../../_images/dbs_03.png" style="width: 480px; height: 300px;" /></a>
</div>
<div class="section" id="id5">
<h3>Algoritmo<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Para cada observación <span class="math notranslate nohighlight">\(x_i\)</span> calcular la distancia entre ella y el resto de observaciones. Si en su  <span class="math notranslate nohighlight">\(epsilon\)</span> -neighborhood hay un número de observaciones <span class="math notranslate nohighlight">\(\geq min_samples\)</span>  marcar la observación como core point, de lo contrario marcarla como visitada.</p></li>
<li><p>Para cada observación  <span class="math notranslate nohighlight">\(x_i\)</span>   marcada como core point, si todavía no ha sido asignada a ningún cluster, crear uno nuevo y asignarla a él. Encontrar recursivamente todas las observaciones densamente conectadas a ella y asignarlas al mismo cluster.</p></li>
<li><p>Iterar el mismo proceso para todas las observaciones que no hayan sido visitadas.</p></li>
<li><p>Aquellas observaciones que tras haber sido visitadas no pertenecen a ningún cluster se marcan como outliers.</p></li>
</ol>
<p>Como resultado, todo cluster cumple dos propiedades: todos los puntos que forman parte de un mismo cluster están densamente conectados entre ellos y, si una observación <span class="math notranslate nohighlight">\(A\)</span>  es densamente alcanzable desde cualquier otra observación de un cluster, entonces <span class="math notranslate nohighlight">\(A\)</span>  también pertenece al cluster.</p>
</div>
<div class="section" id="hiperparametros">
<h3>Hiperparámetros<a class="headerlink" href="#hiperparametros" title="Permalink to this headline">¶</a></h3>
<p>Como ocurre en muchas otras técnicas estadísticas, en DBSCAN no existe una forma única y exacta de encontrar el valor adecuado de epsilon  (<span class="math notranslate nohighlight">\(\epsilon\)</span>))  y  <span class="math notranslate nohighlight">\(min_samples\)</span>) . A modo orientativo se pueden seguir las siguientes premisas:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(min_samples\)</span> : cuanto mayor sea el tamaño del set de datos, mayor debe ser el valor mínimo de observaciones vecinas. En el libro Practical Guide to Cluster Analysis in R recomiendan no bajar nunca de 3. Si los datos contienen niveles altos de ruido, aumentar  <span class="math notranslate nohighlight">\(min_samples\)</span>  favorecerá la creación de clusters significativos menos influenciados por outliers.</p></li>
<li><p>epsilon (<span class="math notranslate nohighlight">\(\epsilon\)</span>): una buena forma de escoger el valor de <span class="math notranslate nohighlight">\(\epsilon\)</span>  es estudiar las distancias promedio entre las  <span class="math notranslate nohighlight">\(k = minsamples𝑠\)</span>  observaciones más próximas. Al representar estas distancias en función de  <span class="math notranslate nohighlight">\(\epsilon\)</span> , el punto de inflexión de la curva suele ser un valor óptimo. Si el valor de  <span class="math notranslate nohighlight">\(\epsilon\)</span> escogido es muy pequeño, una proporción alta de las observaciones no se asignarán a ningún cluster, por el contrario, si el valor es demasiado grande, la mayoría de observaciones se agruparán en un único cluster.</p></li>
</ul>
<div class="section" id="id6">
<h4>Ventajas y desventajas<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>Ventajas</p>
<ul>
<li><p>No requiere que el usuario especifique el número de clusters.</p></li>
<li><p>Es independiente de la forma que tengan los clusters.</p></li>
<li><p>Puede identificar outliers, por lo que los clusters generados no se ven influenciados por ellos.</p></li>
</ul>
</li>
<li><p>Desventajas</p>
<ul>
<li><p>Es un método determinístico siempre y cuando el orden de los datos sea el mismo. Los border points que son alcanzables desde más de un cluster pueden asignarse a uno u otro dependiendo del orden en el que se procesen los datos.</p></li>
<li><p>No genera buenos resultados cuando la densidad de los grupos es muy distinta, ya que no es posible encontrar los parámetros  𝜖  y min_samples que sirvan para todos a la vez.</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="id7">
<h3>Aplicación<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>Veamos un ejemplo de análisis no supervisado ocupando el algoritmo <strong>DBSCAN</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tratamiento de datos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="c1"># Gráficos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">style</span>
<span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

<span class="c1"># Preprocesado y modelado</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="c1"># Configuración warnings</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/multishape.csv&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
      <th>shape</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.803739</td>
      <td>-0.853053</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.852851</td>
      <td>0.367618</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.927180</td>
      <td>-0.274902</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.752626</td>
      <td>-0.511565</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.706846</td>
      <td>0.810679</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar </span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mf">11.7</span><span class="p">,</span><span class="mf">8.27</span><span class="p">)})</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_53_0.png" src="../../../../_images/03_clustering_53_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Escalado de datos</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
      <th>shape</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.120749</td>
      <td>-0.193616</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.448907</td>
      <td>0.844692</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.564203</td>
      <td>0.298161</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.041463</td>
      <td>0.096855</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.222429</td>
      <td>1.221561</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Modelo</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]])</span>

<span class="n">modelo_dbscan</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span>
                    <span class="n">eps</span>          <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
                    <span class="n">min_samples</span>  <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                    <span class="n">metric</span>       <span class="o">=</span> <span class="s1">&#39;euclidean&#39;</span><span class="p">,</span>
                <span class="p">)</span>


<span class="n">modelo_dbscan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DBSCAN(eps=0.2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># agregar labels</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">modelo_dbscan</span><span class="o">.</span><span class="n">labels_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar </span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mf">11.7</span><span class="p">,</span><span class="mf">8.27</span><span class="p">)})</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span><span class="n">hue</span> <span class="o">=</span> <span class="s2">&quot;labels&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_57_0.png" src="../../../../_images/03_clustering_57_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Número de clusters y observaciones &quot;outliers&quot;</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">n_noise</span>    <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Número de clusters encontrados: </span><span class="si">{</span><span class="n">n_clusters</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Número de outliers encontrados: </span><span class="si">{</span><span class="n">n_noise</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Número de clusters encontrados: 6
Número de outliers encontrados: 25
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="gaussian-mixture-models-gmms">
<h2>Gaussian mixture models (GMMs)<a class="headerlink" href="#gaussian-mixture-models-gmms" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id8">
<h3>Teoría<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>Un <a class="reference external" href="https://brilliant.org/wiki/gaussian-mixture-model/">Gaussian Mixture model</a> es un modelo probabilístico en el que se considera que las observaciones siguen una distribución probabilística formada por la combinación de múltiples distribuciones normales (componentes). En su aplicación al clustering, puede entenderse como una generalización de <em>K-means</em> con la que, en lugar de asignar cada observación a un único cluster, se obtiene una probabilidad de pertenencia a cada uno.</p>
<p>Para estimar los parámetros que definen la función de distribución de cada cluster (media y matriz de covarianza) se recurre al algoritmo de Expectation-Maximization (EM). Una vez aprendidos los parámetros, se puede calcular la probabilidad que tiene cada observación de pertenecer a cada cluster y asignarla a aquel con mayor probabilidad.</p>
<img alt="../../../../_images/gmm_01.png" class="align-center" src="../../../../_images/gmm_01.png" />
</div>
<div class="section" id="id9">
<h3>Algoritmo<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>Junto con el número de clusters (componentes), hay que determinar el tipo de matriz de covarianza que pueden tener los clusters. Dependiendo del tipo de matriz, la forma de los clusters puede ser:</p>
<ul class="simple">
<li><p>tied: todos los clusters comparten la misma matriz de covarianza.</p></li>
<li><p>diagonal: las dimensiones de cada cluster a lo largo de cada dimensión puede ser distinto, pero las elipses generadas siempre quedan alineadas con los ejes, es decir, su orientaciones son limitadas.</p></li>
<li><p>spherical: las dimensiones de cada cluster son las mismas en todas las dimensiones. Esto permite generar clusters de distinto tamaño pero todos esféricos.</p></li>
<li><p>full: cada cluster puede puede ser modelado como una elipse cualquier orientación y dimensiones.</p></li>
</ul>
</div>
<div class="section" id="id10">
<h3>Aplicación<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tratamiento de datos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="c1"># Gráficos</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Ellipse</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">style</span>
<span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

<span class="c1"># Preprocesado y modelado</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="c1"># Configuración warnings</span>
<span class="c1"># ==============================================================================</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generar datos</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span>
        <span class="n">n_samples</span>    <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> 
        <span class="n">n_features</span>   <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> 
        <span class="n">centers</span>      <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> 
        <span class="n">cluster_std</span>  <span class="o">=</span> <span class="mf">0.60</span><span class="p">,</span> 
        <span class="n">shuffle</span>      <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
        <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span>
       <span class="p">)</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;x&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
    <span class="s1">&#39;y&#39;</span><span class="p">:</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="p">})</span>


<span class="c1"># Escalado de datos</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">])</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.516255</td>
      <td>-0.707227</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.861664</td>
      <td>1.329068</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.711174</td>
      <td>0.437049</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.619792</td>
      <td>1.485573</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.782282</td>
      <td>-0.801378</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># graficar </span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mf">11.7</span><span class="p">,</span><span class="mf">8.27</span><span class="p">)})</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_62_0.png" src="../../../../_images/03_clustering_62_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Modelo</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;x&#39;</span><span class="p">,</span><span class="s1">&#39;y&#39;</span><span class="p">]])</span>
<span class="n">modelo_gmm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">covariance_type</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">modelo_gmm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GaussianMixture(n_components=4, random_state=123)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Media de cada componente</span>
<span class="n">modelo_gmm</span><span class="o">.</span><span class="n">means_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 0.57844185,  0.17292982],
       [ 1.2180002 , -1.19725866],
       [-0.96910551, -0.44143927],
       [-0.83710796,  1.46219241]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Matriz de covarianza de cada componente</span>
<span class="n">modelo_gmm</span><span class="o">.</span><span class="n">covariances_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[[ 0.14277634, -0.00527707],
        [-0.00527707,  0.05201453]],

       [[ 0.12745218, -0.00619666],
        [-0.00619666,  0.05157763]],

       [[ 0.12131004,  0.00243031],
        [ 0.00243031,  0.04602115]],

       [[ 0.15451151,  0.0068188 ],
        [ 0.0068188 ,  0.05660383]]])
</pre></div>
</div>
</div>
</div>
<p><strong>Predicción y clasificación</strong></p>
<p>Una vez entrenado el modelo GMMs, se puede predecir la probabilidad que tiene cada observación de pertenecer a cada una de las componentes (clusters). Para obtener la clasificación final, se asigna a la componente con mayor probabilidad</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Probabilidades</span>
<span class="c1"># ==============================================================================</span>
<span class="c1"># Cada fila es una observación y cada columna la probabilidad de pertenecer a</span>
<span class="c1"># cada una de las componentes.</span>
<span class="n">probabilidades</span> <span class="o">=</span> <span class="n">modelo_gmm</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">probabilidades</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[2.59319058e-02, 9.71686641e-01, 2.38145325e-03, 8.05199375e-21],
       [7.16006205e-09, 7.13831446e-33, 2.34989165e-15, 9.99999993e-01],
       [9.99999970e-01, 8.78380305e-12, 9.13663813e-09, 2.04805600e-08],
       ...,
       [9.99965889e-01, 4.92493619e-10, 3.41016281e-05, 8.75675460e-09],
       [3.01319652e-06, 6.45628361e-30, 1.52897049e-18, 9.99996987e-01],
       [4.39337172e-07, 1.99785604e-11, 9.99999561e-01, 4.05381245e-15]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Clasificación (asignación a la componente de mayor probabilidad)</span>
<span class="c1"># ==============================================================================</span>
<span class="c1"># Cada fila es una observación y cada columna la probabilidad de pertenecer a</span>
<span class="c1"># cada una de las componentes.</span>
<span class="n">clasificacion</span> <span class="o">=</span> <span class="n">modelo_gmm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">clasificacion</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1, 3, 0, 3, 1, 1, 2, 0, 3, 3, 2, 3, 0, 3, 1, 0, 0, 1, 2, 2, 1, 1,
       0, 2, 2, 0, 1, 0, 2, 0, 3, 3, 0, 3, 3, 3, 3, 3, 2, 1, 0, 2, 0, 0,
       2, 2, 3, 2, 3, 1, 2, 1, 3, 1, 1, 2, 3, 2, 3, 1, 3, 0, 3, 2, 2, 2,
       3, 1, 3, 2, 0, 2, 3, 2, 2, 3, 2, 0, 1, 3, 1, 0, 1, 1, 3, 0, 1, 0,
       3, 3, 0, 1, 3, 2, 2, 0, 1, 1, 0, 2, 3, 1, 3, 1, 0, 1, 1, 0, 3, 0,
       2, 2, 1, 3, 1, 0, 3, 1, 1, 0, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 3, 2,
       2, 1, 3, 2, 2, 3, 0, 3, 3, 2, 0, 2, 0, 2, 3, 0, 3, 3, 3, 0, 3, 0,
       1, 2, 3, 2, 1, 0, 3, 0, 0, 1, 0, 2, 2, 0, 1, 0, 0, 3, 1, 0, 2, 3,
       1, 1, 0, 2, 1, 0, 2, 2, 0, 0, 0, 0, 1, 3, 0, 2, 0, 0, 2, 2, 2, 0,
       2, 3, 0, 2, 1, 2, 0, 3, 2, 3, 0, 3, 0, 2, 0, 0, 3, 2, 2, 1, 1, 0,
       3, 1, 1, 2, 1, 2, 0, 3, 3, 0, 0, 3, 0, 1, 2, 0, 1, 2, 3, 2, 1, 0,
       1, 3, 3, 3, 3, 2, 2, 3, 0, 2, 1, 0, 2, 2, 2, 1, 1, 3, 0, 0, 2, 1,
       3, 2, 0, 3, 0, 1, 1, 2, 2, 0, 1, 1, 1, 0, 3, 3, 1, 1, 0, 1, 1, 1,
       3, 2, 3, 0, 1, 1, 3, 3, 3, 1, 1, 0, 3, 2])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Representación gráfica</span>
<span class="c1"># ==============================================================================</span>
<span class="c1"># Codigo obtenido de:</span>
<span class="c1"># https://github.com/amueller/COMS4995-s20/tree/master/slides/aml-14-clustering-mixture-models </span>
<span class="k">def</span> <span class="nf">make_ellipses</span><span class="p">(</span><span class="n">gmm</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariance_type</span> <span class="o">==</span> <span class="s1">&#39;full&#39;</span><span class="p">:</span>
            <span class="n">covariances</span> <span class="o">=</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariances_</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariance_type</span> <span class="o">==</span> <span class="s1">&#39;tied&#39;</span><span class="p">:</span>
            <span class="n">covariances</span> <span class="o">=</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariances_</span>
        <span class="k">elif</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariance_type</span> <span class="o">==</span> <span class="s1">&#39;diag&#39;</span><span class="p">:</span>
            <span class="n">covariances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">covariances_</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariance_type</span> <span class="o">==</span> <span class="s1">&#39;spherical&#39;</span><span class="p">:</span>
            <span class="n">covariances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">means_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">gmm</span><span class="o">.</span><span class="n">covariances_</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
        <span class="n">v</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">covariances</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">angle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">u</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">angle</span> <span class="o">=</span> <span class="mi">180</span> <span class="o">*</span> <span class="n">angle</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>  <span class="c1"># convert to degrees</span>
        <span class="n">v</span> <span class="o">=</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">ell</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">patches</span><span class="o">.</span><span class="n">Ellipse</span><span class="p">(</span><span class="n">gmm</span><span class="o">.</span><span class="n">means_</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">i</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">i</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                      <span class="mi">180</span> <span class="o">+</span> <span class="n">angle</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
            <span class="n">ell</span><span class="o">.</span><span class="n">set_clip_box</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">bbox</span><span class="p">)</span>
            <span class="n">ell</span><span class="o">.</span><span class="n">set_alpha</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">ell</span><span class="p">)</span>
        
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Distribución de probabilidad de cada componente</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">clasificacion</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">clasificacion</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">clasificacion</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
        <span class="n">c</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.prop_cycle&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">by_key</span><span class="p">()[</span><span class="s1">&#39;color&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">],</span>
        <span class="n">marker</span>    <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span>
        <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> 
        <span class="n">label</span><span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Componente </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>

<span class="n">make_ellipses</span><span class="p">(</span><span class="n">modelo_gmm</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Distribución de prob. de cada componente&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>


<span class="c1"># Distribución de probabilidad del modelo completo</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]),</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">modelo_gmm</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()],</span> <span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.6</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">tab10</span><span class="p">(</span><span class="n">clasificacion</span><span class="p">))</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span> <span class="c1"># Las probabilidades están en log</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
    <span class="n">levels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">))[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Distribución de prob. del modelo completo&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* &amp; *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* &amp; *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* &amp; *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* &amp; *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.
</pre></div>
</div>
<img alt="../../../../_images/03_clustering_70_4.png" src="../../../../_images/03_clustering_70_4.png" />
</div>
</div>
<p><strong>Número de clusters</strong></p>
<p>Dado que los modelos GMM son modelos probabilísticos, se puede recurrir a métricas como el Akaike information criterion (AIC) o Bayesian information criterion (BIC) para identificar cómo de bien se ajustan los datos observados a modelo creado.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_components</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
<span class="n">valores_bic</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valores_aic</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">n_components</span><span class="p">:</span>
    <span class="n">modelo</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">covariance_type</span><span class="o">=</span><span class="s2">&quot;full&quot;</span><span class="p">)</span>
    <span class="n">modelo</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">valores_bic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">modelo</span><span class="o">.</span><span class="n">bic</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    <span class="n">valores_aic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">modelo</span><span class="o">.</span><span class="n">aic</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">valores_bic</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;BIC&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">valores_aic</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;AIC&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Valores BIC y AIC&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Número componentes&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/03_clustering_72_0.png" src="../../../../_images/03_clustering_72_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Número óptimo acorde al BIC: </span><span class="si">{</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">valores_bic</span><span class="p">)]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Número óptimo acorde al AIC: </span><span class="si">{</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">valores_aic</span><span class="p">)]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Número óptimo acorde al BIC: 4
Número óptimo acorde al AIC: 4
</pre></div>
</div>
</div>
</div>
<p>Ambas métricas identifican el 4 como número óptimo de clusters (componentes).</p>
</div>
</div>
<div class="section" id="limitaciones-del-clustering">
<h2>Limitaciones del clustering<a class="headerlink" href="#limitaciones-del-clustering" title="Permalink to this headline">¶</a></h2>
<p>El clustering puede ser una herramienta muy útil para encontrar agrupaciones en los datos, sobre todo a medida que el volumen de los mismos aumenta. Sin embargo, es importante recordar sus limitaciones o problemas que pueden surgir al aplicarlo. Algunas de ellas son:</p>
<ul class="simple">
<li><p>Pequeñas decisiones pueden tener grandes consecuencias:a la hora de utilizar los métodos de clustering se tienen que tomar decisiones que influyen en gran medida en los resultados obtenidos. No existe una única respuesta correcta, por lo que en la práctica se prueban diferentes opciones.</p>
<ul>
<li><p>Escalado y centrado de las variables</p></li>
<li><p>Qué medida de distancia/similitud emplear</p></li>
<li><p>Número de clusters</p></li>
<li><p>Tipo de linkage empleado en hierarchical clustering</p></li>
<li><p>A que altura establecer el corte de un dendrograma</p></li>
</ul>
</li>
<li><p>Validación de los clusters obtenidos: no es fácil comprobar la validez de los resultados ya que en la mayoría de escenarios se desconoce la verdadera agrupación.</p></li>
<li><p>Falta de robustez: los métodos de K-means-clustering e hierarchical clustering asignan obligatoriamente cada observación a un grupo. Si existe en la muestra algún outlier, a pesar de que realmente no pertenezca a ningún grupo, el algoritmo lo asignará a uno de ellos provocando una distorsión significativa del cluster en cuestión. Algunas alternativas son k-medoids y DBSCAN.</p></li>
<li><p>La naturaleza del algoritmo de hierarchical clustering conlleva que, si se realiza una mala división en los pasos iniciales, no se pueda corregir en los pasos siguientes.</p></li>
</ul>
</div>
<div class="section" id="referencias">
<h2>Referencias<a class="headerlink" href="#referencias" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org/stable/unsupervised_learning.html">Unsupervised learning</a></p></li>
<li><p><a class="reference external" href="https://www.cienciadedatos.net/documentos/py20-clustering-con-python.html">Clustering con Python (Joaquín Amat Rodrigo)</a></p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./mat281/lectures/ml/analisis_no_supervisado"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../introduccion_ml/no_supervisados.html" title="previous page">Aprendizaje no supervisado</a>
    <a class='right-next' id="next-link" href="03_reduccion_dimensionalidad.html" title="next page">Reducción de dimensionalidad</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Francisco Alfaro Medina<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-177357392-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>